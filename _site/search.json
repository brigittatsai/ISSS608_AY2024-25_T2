[
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#install-and-load-r-packages",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#install-and-load-r-packages",
    "title": "In-class Exercise 8",
    "section": "1.1 Install and Load R Packages",
    "text": "1.1 Install and Load R Packages\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#import-geospatial-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#import-geospatial-data",
    "title": "In-class Exercise 8",
    "section": "1.2 Import Geospatial Data",
    "text": "1.2 Import Geospatial Data\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\brigittatsai\\ISSS608_AY2024-25_T2\\In-class_Ex\\In-class_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#importing-attribute-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#importing-attribute-data",
    "title": "In-class Exercise 8",
    "section": "1.3 Importing Attribute Data",
    "text": "1.3 Importing Attribute Data\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-wrangling",
    "title": "In-class Exercise 8",
    "section": "2.1 Data Wrangling",
    "text": "2.1 Data Wrangling\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#joining-geospatial-and-aspatial-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#joining-geospatial-and-aspatial-data",
    "title": "In-class Exercise 8",
    "section": "2.2 Joining Geospatial and Aspatial Data",
    "text": "2.2 Joining Geospatial and Aspatial Data\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#qtm",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#qtm",
    "title": "In-class Exercise 8",
    "section": "3.1 qtm()",
    "text": "3.1 qtm()\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#tmaps-elements",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#tmaps-elements",
    "title": "In-class Exercise 8",
    "section": "3.2 tmap’s elements",
    "text": "3.2 tmap’s elements\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n3.2.1 Drawing a base map\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n3.2.2 Drawing a choropleth map using tm_polygons()\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\n\n3.2.3 Drawing a choropleth map using tm_fill() and tm_border()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nAdd the borders using tm_borders()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_borders()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\nThis message is displayed once every 8 hours."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-classification-methods-of-tmap",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-classification-methods-of-tmap",
    "title": "In-class Exercise 8",
    "section": "3.3 Data Classification Methods of tmap",
    "text": "3.3 Data Classification Methods of tmap\n\n3.3.1 Plotting choropleth maps with built-in classification methods\n\nJenksEqual\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"jenks\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'n' to 'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"equal\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'n' to 'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.2 Plotting choropleth map with custome break\nBefore setting break points, it is always good to display and compute the descriptive statistics using the code below.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_tm_fill()`: migrate the argument(s) related to the scale of the\nvisual variable `fill` namely 'breaks' to fill.scale = tm_scale(&lt;HERE&gt;).\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n\n\nWarning: Values have found that are higher than the highest break. They are\nassigned to the highest interval"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#colour-scheme",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#colour-scheme",
    "title": "In-class Exercise 8",
    "section": "3.4 Colour Scheme",
    "text": "3.4 Colour Scheme\n\n3.4.1 ColourBrewer Palette\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'n', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") + # Use '-' to reverse colour shading\n  tm_borders(alpha = 0.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\nMultiple palettes called \"greens\" found: \"brewer.greens\", \"matplotlib.greens\". The first one, \"brewer.greens\", is returned.\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-Greens\" is named\n\"greens\" (in long format \"brewer.greens\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#map-layouts",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#map-layouts",
    "title": "In-class Exercise 8",
    "section": "3.5 Map Layouts",
    "text": "3.5 Map Layouts\n\n3.5.1 Map Legends\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"jenks\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_fill()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'legend.is.portrait' (rename to 'orientation') to\n'fill.legend = tm_legend(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_fill()`: use `fill.chart = tm_chart_histogram()` instead of\n`legend.hist = TRUE`.\n[v3-&gt;v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n\n\n\n\n\n\n\n\n\n\n\n3.5.2 Map Style\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\nstyle set to \"classic\"\n\nother available styles are: \"white\" (tmap default), \"gray\", \"natural\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"watercolor\"\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\"\n\nMultiple palettes called \"greens\" found: \"brewer.greens\", \"matplotlib.greens\". The first one, \"brewer.greens\", is returned.\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-Greens\" is named\n\"greens\" (in long format \"brewer.greens\")\n\n\n\n\n\n\n\n\n\n\n\n3.5.3 Cartographic Furniture\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nUse the code below to reset to default style\n\ntmap_style(\"white\")\n\nstyle set to \"white\" (tmap default)\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#drawing-small-multiple-choropleth-maps",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#drawing-small-multiple-choropleth-maps",
    "title": "In-class Exercise 8",
    "section": "3.6 Drawing Small Multiple Choropleth Maps",
    "text": "3.6 Drawing Small Multiple Choropleth Maps\n\n3.6.1 By Assigning Multiple Values to at least one of The Aesthetic Arguments\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"equal\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\nstyle set to \"white\" (tmap default)\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\"\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_polygons()`: instead of `style = \"equal\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'\nFor small multiples, specify a 'tm_scale_' for each multiple, and put them in a\nlist: 'fill'.scale = list(&lt;scale1&gt;, &lt;scale2&gt;, ...)'\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n\n\n\n\n\n\n\n\n\n\n\n3.6.2 By defining a groupby variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n\n\n\n\n\n\n\n\n\n\n\n3.6.3 By Creating Multiple Stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_polygons()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned.\n\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "In-class Exercise 8",
    "section": "3.7 Mapping Spatial Object Meeting a Selection Criterion",
    "text": "3.7 Mapping Spatial Object Meeting a Selection Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_fill()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'palette' (rename to 'values') to\n  'tm_scale_intervals(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_fill()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'legend.is.portrait' (rename to 'orientation') to\n'fill.legend = tm_legend(&lt;HERE&gt;)'\n[v3-&gt;v4] `tm_borders()`: use `fill_alpha` instead of `alpha`.\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"Blues\" is named\n\"brewer.blues\"\nMultiple palettes called \"blues\" found: \"brewer.blues\", \"matplotlib.blues\". The first one, \"brewer.blues\", is returned."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-background",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-background",
    "title": "Take-home Exercise 2",
    "section": "1.1 The Background",
    "text": "1.1 The Background\nThe purpose of this analysis is to visualize the trends and patterns of Singapore international trade. By using historical data, we will find out the meaning behind these data and derive meaningful insights."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "title": "Take-home Exercise 2",
    "section": "1.2 The Data",
    "text": "1.2 The Data\nFor this analysis, the data will be taken from SingStat, the following are the list of data used:\n\nMerchandise Trade by Region and Selected Markets\n\nImports\nDomestic Exports\nRe-Exports"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-task",
    "title": "Take-home Exercise 2",
    "section": "1.3 The Task",
    "text": "1.3 The Task\nThere are several tasks assigned for this paper:\n\nSelect 3 visualisations from this page, comment the pros and cons and provide the sketches of the make-over\nCreate the makeover of the 3 data visualisation critic\nAnalyse the data with time-series analysis by complimenting the analysis using appropriate visualisation methods"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#install-and-load-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#install-and-load-r-packages",
    "title": "Take-home Exercise 2",
    "section": "2.1 Install and Load R Packages",
    "text": "2.1 Install and Load R Packages\n\npacman::p_load(tidyverse, tsibble, feasts, fable, seasonal, lubridate,\n               data.table, dplyr)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-data",
    "title": "Take-home Exercise 2",
    "section": "2.2 Import Data",
    "text": "2.2 Import Data\nIn this section, we will import 3 datasets, Imports, Domestic Exports and Re-Exports.\n\nImportsDomestic ExportsRe-Exports\n\n\n\nimports &lt;- read_csv(\"data/imports.csv\")\n\nNew names:\nRows: 187 Columns: 266\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(266): ...1, ...2, ...3, ...4, ...5, ...6, ...7, ...8, ...9, ...10, ...1...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...12`\n• `` -&gt; `...13`\n• `` -&gt; `...14`\n• `` -&gt; `...15`\n• `` -&gt; `...16`\n• `` -&gt; `...17`\n• `` -&gt; `...18`\n• `` -&gt; `...19`\n• `` -&gt; `...20`\n• `` -&gt; `...21`\n• `` -&gt; `...22`\n• `` -&gt; `...23`\n• `` -&gt; `...24`\n• `` -&gt; `...25`\n• `` -&gt; `...26`\n• `` -&gt; `...27`\n• `` -&gt; `...28`\n• `` -&gt; `...29`\n• `` -&gt; `...30`\n• `` -&gt; `...31`\n• `` -&gt; `...32`\n• `` -&gt; `...33`\n• `` -&gt; `...34`\n• `` -&gt; `...35`\n• `` -&gt; `...36`\n• `` -&gt; `...37`\n• `` -&gt; `...38`\n• `` -&gt; `...39`\n• `` -&gt; `...40`\n• `` -&gt; `...41`\n• `` -&gt; `...42`\n• `` -&gt; `...43`\n• `` -&gt; `...44`\n• `` -&gt; `...45`\n• `` -&gt; `...46`\n• `` -&gt; `...47`\n• `` -&gt; `...48`\n• `` -&gt; `...49`\n• `` -&gt; `...50`\n• `` -&gt; `...51`\n• `` -&gt; `...52`\n• `` -&gt; `...53`\n• `` -&gt; `...54`\n• `` -&gt; `...55`\n• `` -&gt; `...56`\n• `` -&gt; `...57`\n• `` -&gt; `...58`\n• `` -&gt; `...59`\n• `` -&gt; `...60`\n• `` -&gt; `...61`\n• `` -&gt; `...62`\n• `` -&gt; `...63`\n• `` -&gt; `...64`\n• `` -&gt; `...65`\n• `` -&gt; `...66`\n• `` -&gt; `...67`\n• `` -&gt; `...68`\n• `` -&gt; `...69`\n• `` -&gt; `...70`\n• `` -&gt; `...71`\n• `` -&gt; `...72`\n• `` -&gt; `...73`\n• `` -&gt; `...74`\n• `` -&gt; `...75`\n• `` -&gt; `...76`\n• `` -&gt; `...77`\n• `` -&gt; `...78`\n• `` -&gt; `...79`\n• `` -&gt; `...80`\n• `` -&gt; `...81`\n• `` -&gt; `...82`\n• `` -&gt; `...83`\n• `` -&gt; `...84`\n• `` -&gt; `...85`\n• `` -&gt; `...86`\n• `` -&gt; `...87`\n• `` -&gt; `...88`\n• `` -&gt; `...89`\n• `` -&gt; `...90`\n• `` -&gt; `...91`\n• `` -&gt; `...92`\n• `` -&gt; `...93`\n• `` -&gt; `...94`\n• `` -&gt; `...95`\n• `` -&gt; `...96`\n• `` -&gt; `...97`\n• `` -&gt; `...98`\n• `` -&gt; `...99`\n• `` -&gt; `...100`\n• `` -&gt; `...101`\n• `` -&gt; `...102`\n• `` -&gt; `...103`\n• `` -&gt; `...104`\n• `` -&gt; `...105`\n• `` -&gt; `...106`\n• `` -&gt; `...107`\n• `` -&gt; `...108`\n• `` -&gt; `...109`\n• `` -&gt; `...110`\n• `` -&gt; `...111`\n• `` -&gt; `...112`\n• `` -&gt; `...113`\n• `` -&gt; `...114`\n• `` -&gt; `...115`\n• `` -&gt; `...116`\n• `` -&gt; `...117`\n• `` -&gt; `...118`\n• `` -&gt; `...119`\n• `` -&gt; `...120`\n• `` -&gt; `...121`\n• `` -&gt; `...122`\n• `` -&gt; `...123`\n• `` -&gt; `...124`\n• `` -&gt; `...125`\n• `` -&gt; `...126`\n• `` -&gt; `...127`\n• `` -&gt; `...128`\n• `` -&gt; `...129`\n• `` -&gt; `...130`\n• `` -&gt; `...131`\n• `` -&gt; `...132`\n• `` -&gt; `...133`\n• `` -&gt; `...134`\n• `` -&gt; `...135`\n• `` -&gt; `...136`\n• `` -&gt; `...137`\n• `` -&gt; `...138`\n• `` -&gt; `...139`\n• `` -&gt; `...140`\n• `` -&gt; `...141`\n• `` -&gt; `...142`\n• `` -&gt; `...143`\n• `` -&gt; `...144`\n• `` -&gt; `...145`\n• `` -&gt; `...146`\n• `` -&gt; `...147`\n• `` -&gt; `...148`\n• `` -&gt; `...149`\n• `` -&gt; `...150`\n• `` -&gt; `...151`\n• `` -&gt; `...152`\n• `` -&gt; `...153`\n• `` -&gt; `...154`\n• `` -&gt; `...155`\n• `` -&gt; `...156`\n• `` -&gt; `...157`\n• `` -&gt; `...158`\n• `` -&gt; `...159`\n• `` -&gt; `...160`\n• `` -&gt; `...161`\n• `` -&gt; `...162`\n• `` -&gt; `...163`\n• `` -&gt; `...164`\n• `` -&gt; `...165`\n• `` -&gt; `...166`\n• `` -&gt; `...167`\n• `` -&gt; `...168`\n• `` -&gt; `...169`\n• `` -&gt; `...170`\n• `` -&gt; `...171`\n• `` -&gt; `...172`\n• `` -&gt; `...173`\n• `` -&gt; `...174`\n• `` -&gt; `...175`\n• `` -&gt; `...176`\n• `` -&gt; `...177`\n• `` -&gt; `...178`\n• `` -&gt; `...179`\n• `` -&gt; `...180`\n• `` -&gt; `...181`\n• `` -&gt; `...182`\n• `` -&gt; `...183`\n• `` -&gt; `...184`\n• `` -&gt; `...185`\n• `` -&gt; `...186`\n• `` -&gt; `...187`\n• `` -&gt; `...188`\n• `` -&gt; `...189`\n• `` -&gt; `...190`\n• `` -&gt; `...191`\n• `` -&gt; `...192`\n• `` -&gt; `...193`\n• `` -&gt; `...194`\n• `` -&gt; `...195`\n• `` -&gt; `...196`\n• `` -&gt; `...197`\n• `` -&gt; `...198`\n• `` -&gt; `...199`\n• `` -&gt; `...200`\n• `` -&gt; `...201`\n• `` -&gt; `...202`\n• `` -&gt; `...203`\n• `` -&gt; `...204`\n• `` -&gt; `...205`\n• `` -&gt; `...206`\n• `` -&gt; `...207`\n• `` -&gt; `...208`\n• `` -&gt; `...209`\n• `` -&gt; `...210`\n• `` -&gt; `...211`\n• `` -&gt; `...212`\n• `` -&gt; `...213`\n• `` -&gt; `...214`\n• `` -&gt; `...215`\n• `` -&gt; `...216`\n• `` -&gt; `...217`\n• `` -&gt; `...218`\n• `` -&gt; `...219`\n• `` -&gt; `...220`\n• `` -&gt; `...221`\n• `` -&gt; `...222`\n• `` -&gt; `...223`\n• `` -&gt; `...224`\n• `` -&gt; `...225`\n• `` -&gt; `...226`\n• `` -&gt; `...227`\n• `` -&gt; `...228`\n• `` -&gt; `...229`\n• `` -&gt; `...230`\n• `` -&gt; `...231`\n• `` -&gt; `...232`\n• `` -&gt; `...233`\n• `` -&gt; `...234`\n• `` -&gt; `...235`\n• `` -&gt; `...236`\n• `` -&gt; `...237`\n• `` -&gt; `...238`\n• `` -&gt; `...239`\n• `` -&gt; `...240`\n• `` -&gt; `...241`\n• `` -&gt; `...242`\n• `` -&gt; `...243`\n• `` -&gt; `...244`\n• `` -&gt; `...245`\n• `` -&gt; `...246`\n• `` -&gt; `...247`\n• `` -&gt; `...248`\n• `` -&gt; `...249`\n• `` -&gt; `...250`\n• `` -&gt; `...251`\n• `` -&gt; `...252`\n• `` -&gt; `...253`\n• `` -&gt; `...254`\n• `` -&gt; `...255`\n• `` -&gt; `...256`\n• `` -&gt; `...257`\n• `` -&gt; `...258`\n• `` -&gt; `...259`\n• `` -&gt; `...260`\n• `` -&gt; `...261`\n• `` -&gt; `...262`\n• `` -&gt; `...263`\n• `` -&gt; `...264`\n• `` -&gt; `...265`\n• `` -&gt; `...266`\n\n\n\n\n\ndom_exports &lt;- read_csv(\"data/dom_exports.csv\")\n\nNew names:\nRows: 191 Columns: 266\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(266): ...1, ...2, ...3, ...4, ...5, ...6, ...7, ...8, ...9, ...10, ...1...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...12`\n• `` -&gt; `...13`\n• `` -&gt; `...14`\n• `` -&gt; `...15`\n• `` -&gt; `...16`\n• `` -&gt; `...17`\n• `` -&gt; `...18`\n• `` -&gt; `...19`\n• `` -&gt; `...20`\n• `` -&gt; `...21`\n• `` -&gt; `...22`\n• `` -&gt; `...23`\n• `` -&gt; `...24`\n• `` -&gt; `...25`\n• `` -&gt; `...26`\n• `` -&gt; `...27`\n• `` -&gt; `...28`\n• `` -&gt; `...29`\n• `` -&gt; `...30`\n• `` -&gt; `...31`\n• `` -&gt; `...32`\n• `` -&gt; `...33`\n• `` -&gt; `...34`\n• `` -&gt; `...35`\n• `` -&gt; `...36`\n• `` -&gt; `...37`\n• `` -&gt; `...38`\n• `` -&gt; `...39`\n• `` -&gt; `...40`\n• `` -&gt; `...41`\n• `` -&gt; `...42`\n• `` -&gt; `...43`\n• `` -&gt; `...44`\n• `` -&gt; `...45`\n• `` -&gt; `...46`\n• `` -&gt; `...47`\n• `` -&gt; `...48`\n• `` -&gt; `...49`\n• `` -&gt; `...50`\n• `` -&gt; `...51`\n• `` -&gt; `...52`\n• `` -&gt; `...53`\n• `` -&gt; `...54`\n• `` -&gt; `...55`\n• `` -&gt; `...56`\n• `` -&gt; `...57`\n• `` -&gt; `...58`\n• `` -&gt; `...59`\n• `` -&gt; `...60`\n• `` -&gt; `...61`\n• `` -&gt; `...62`\n• `` -&gt; `...63`\n• `` -&gt; `...64`\n• `` -&gt; `...65`\n• `` -&gt; `...66`\n• `` -&gt; `...67`\n• `` -&gt; `...68`\n• `` -&gt; `...69`\n• `` -&gt; `...70`\n• `` -&gt; `...71`\n• `` -&gt; `...72`\n• `` -&gt; `...73`\n• `` -&gt; `...74`\n• `` -&gt; `...75`\n• `` -&gt; `...76`\n• `` -&gt; `...77`\n• `` -&gt; `...78`\n• `` -&gt; `...79`\n• `` -&gt; `...80`\n• `` -&gt; `...81`\n• `` -&gt; `...82`\n• `` -&gt; `...83`\n• `` -&gt; `...84`\n• `` -&gt; `...85`\n• `` -&gt; `...86`\n• `` -&gt; `...87`\n• `` -&gt; `...88`\n• `` -&gt; `...89`\n• `` -&gt; `...90`\n• `` -&gt; `...91`\n• `` -&gt; `...92`\n• `` -&gt; `...93`\n• `` -&gt; `...94`\n• `` -&gt; `...95`\n• `` -&gt; `...96`\n• `` -&gt; `...97`\n• `` -&gt; `...98`\n• `` -&gt; `...99`\n• `` -&gt; `...100`\n• `` -&gt; `...101`\n• `` -&gt; `...102`\n• `` -&gt; `...103`\n• `` -&gt; `...104`\n• `` -&gt; `...105`\n• `` -&gt; `...106`\n• `` -&gt; `...107`\n• `` -&gt; `...108`\n• `` -&gt; `...109`\n• `` -&gt; `...110`\n• `` -&gt; `...111`\n• `` -&gt; `...112`\n• `` -&gt; `...113`\n• `` -&gt; `...114`\n• `` -&gt; `...115`\n• `` -&gt; `...116`\n• `` -&gt; `...117`\n• `` -&gt; `...118`\n• `` -&gt; `...119`\n• `` -&gt; `...120`\n• `` -&gt; `...121`\n• `` -&gt; `...122`\n• `` -&gt; `...123`\n• `` -&gt; `...124`\n• `` -&gt; `...125`\n• `` -&gt; `...126`\n• `` -&gt; `...127`\n• `` -&gt; `...128`\n• `` -&gt; `...129`\n• `` -&gt; `...130`\n• `` -&gt; `...131`\n• `` -&gt; `...132`\n• `` -&gt; `...133`\n• `` -&gt; `...134`\n• `` -&gt; `...135`\n• `` -&gt; `...136`\n• `` -&gt; `...137`\n• `` -&gt; `...138`\n• `` -&gt; `...139`\n• `` -&gt; `...140`\n• `` -&gt; `...141`\n• `` -&gt; `...142`\n• `` -&gt; `...143`\n• `` -&gt; `...144`\n• `` -&gt; `...145`\n• `` -&gt; `...146`\n• `` -&gt; `...147`\n• `` -&gt; `...148`\n• `` -&gt; `...149`\n• `` -&gt; `...150`\n• `` -&gt; `...151`\n• `` -&gt; `...152`\n• `` -&gt; `...153`\n• `` -&gt; `...154`\n• `` -&gt; `...155`\n• `` -&gt; `...156`\n• `` -&gt; `...157`\n• `` -&gt; `...158`\n• `` -&gt; `...159`\n• `` -&gt; `...160`\n• `` -&gt; `...161`\n• `` -&gt; `...162`\n• `` -&gt; `...163`\n• `` -&gt; `...164`\n• `` -&gt; `...165`\n• `` -&gt; `...166`\n• `` -&gt; `...167`\n• `` -&gt; `...168`\n• `` -&gt; `...169`\n• `` -&gt; `...170`\n• `` -&gt; `...171`\n• `` -&gt; `...172`\n• `` -&gt; `...173`\n• `` -&gt; `...174`\n• `` -&gt; `...175`\n• `` -&gt; `...176`\n• `` -&gt; `...177`\n• `` -&gt; `...178`\n• `` -&gt; `...179`\n• `` -&gt; `...180`\n• `` -&gt; `...181`\n• `` -&gt; `...182`\n• `` -&gt; `...183`\n• `` -&gt; `...184`\n• `` -&gt; `...185`\n• `` -&gt; `...186`\n• `` -&gt; `...187`\n• `` -&gt; `...188`\n• `` -&gt; `...189`\n• `` -&gt; `...190`\n• `` -&gt; `...191`\n• `` -&gt; `...192`\n• `` -&gt; `...193`\n• `` -&gt; `...194`\n• `` -&gt; `...195`\n• `` -&gt; `...196`\n• `` -&gt; `...197`\n• `` -&gt; `...198`\n• `` -&gt; `...199`\n• `` -&gt; `...200`\n• `` -&gt; `...201`\n• `` -&gt; `...202`\n• `` -&gt; `...203`\n• `` -&gt; `...204`\n• `` -&gt; `...205`\n• `` -&gt; `...206`\n• `` -&gt; `...207`\n• `` -&gt; `...208`\n• `` -&gt; `...209`\n• `` -&gt; `...210`\n• `` -&gt; `...211`\n• `` -&gt; `...212`\n• `` -&gt; `...213`\n• `` -&gt; `...214`\n• `` -&gt; `...215`\n• `` -&gt; `...216`\n• `` -&gt; `...217`\n• `` -&gt; `...218`\n• `` -&gt; `...219`\n• `` -&gt; `...220`\n• `` -&gt; `...221`\n• `` -&gt; `...222`\n• `` -&gt; `...223`\n• `` -&gt; `...224`\n• `` -&gt; `...225`\n• `` -&gt; `...226`\n• `` -&gt; `...227`\n• `` -&gt; `...228`\n• `` -&gt; `...229`\n• `` -&gt; `...230`\n• `` -&gt; `...231`\n• `` -&gt; `...232`\n• `` -&gt; `...233`\n• `` -&gt; `...234`\n• `` -&gt; `...235`\n• `` -&gt; `...236`\n• `` -&gt; `...237`\n• `` -&gt; `...238`\n• `` -&gt; `...239`\n• `` -&gt; `...240`\n• `` -&gt; `...241`\n• `` -&gt; `...242`\n• `` -&gt; `...243`\n• `` -&gt; `...244`\n• `` -&gt; `...245`\n• `` -&gt; `...246`\n• `` -&gt; `...247`\n• `` -&gt; `...248`\n• `` -&gt; `...249`\n• `` -&gt; `...250`\n• `` -&gt; `...251`\n• `` -&gt; `...252`\n• `` -&gt; `...253`\n• `` -&gt; `...254`\n• `` -&gt; `...255`\n• `` -&gt; `...256`\n• `` -&gt; `...257`\n• `` -&gt; `...258`\n• `` -&gt; `...259`\n• `` -&gt; `...260`\n• `` -&gt; `...261`\n• `` -&gt; `...262`\n• `` -&gt; `...263`\n• `` -&gt; `...264`\n• `` -&gt; `...265`\n• `` -&gt; `...266`\n\nhead(dom_exports,1)\n\n# A tibble: 1 × 266\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 253 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;, ...26 &lt;chr&gt;, ...27 &lt;chr&gt;,\n#   ...28 &lt;chr&gt;, ...29 &lt;chr&gt;, ...30 &lt;chr&gt;, ...31 &lt;chr&gt;, ...32 &lt;chr&gt;,\n#   ...33 &lt;chr&gt;, ...34 &lt;chr&gt;, ...35 &lt;chr&gt;, ...36 &lt;chr&gt;, ...37 &lt;chr&gt;,\n#   ...38 &lt;chr&gt;, ...39 &lt;chr&gt;, ...40 &lt;chr&gt;, ...41 &lt;chr&gt;, ...42 &lt;chr&gt;,\n#   ...43 &lt;chr&gt;, ...44 &lt;chr&gt;, ...45 &lt;chr&gt;, ...46 &lt;chr&gt;, ...47 &lt;chr&gt;, …\n\n\n\n\n\nre_exports &lt;- read_csv(\"data/re_exports.csv\")\n\nNew names:\nRows: 191 Columns: 266\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(266): ...1, ...2, ...3, ...4, ...5, ...6, ...7, ...8, ...9, ...10, ...1...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...12`\n• `` -&gt; `...13`\n• `` -&gt; `...14`\n• `` -&gt; `...15`\n• `` -&gt; `...16`\n• `` -&gt; `...17`\n• `` -&gt; `...18`\n• `` -&gt; `...19`\n• `` -&gt; `...20`\n• `` -&gt; `...21`\n• `` -&gt; `...22`\n• `` -&gt; `...23`\n• `` -&gt; `...24`\n• `` -&gt; `...25`\n• `` -&gt; `...26`\n• `` -&gt; `...27`\n• `` -&gt; `...28`\n• `` -&gt; `...29`\n• `` -&gt; `...30`\n• `` -&gt; `...31`\n• `` -&gt; `...32`\n• `` -&gt; `...33`\n• `` -&gt; `...34`\n• `` -&gt; `...35`\n• `` -&gt; `...36`\n• `` -&gt; `...37`\n• `` -&gt; `...38`\n• `` -&gt; `...39`\n• `` -&gt; `...40`\n• `` -&gt; `...41`\n• `` -&gt; `...42`\n• `` -&gt; `...43`\n• `` -&gt; `...44`\n• `` -&gt; `...45`\n• `` -&gt; `...46`\n• `` -&gt; `...47`\n• `` -&gt; `...48`\n• `` -&gt; `...49`\n• `` -&gt; `...50`\n• `` -&gt; `...51`\n• `` -&gt; `...52`\n• `` -&gt; `...53`\n• `` -&gt; `...54`\n• `` -&gt; `...55`\n• `` -&gt; `...56`\n• `` -&gt; `...57`\n• `` -&gt; `...58`\n• `` -&gt; `...59`\n• `` -&gt; `...60`\n• `` -&gt; `...61`\n• `` -&gt; `...62`\n• `` -&gt; `...63`\n• `` -&gt; `...64`\n• `` -&gt; `...65`\n• `` -&gt; `...66`\n• `` -&gt; `...67`\n• `` -&gt; `...68`\n• `` -&gt; `...69`\n• `` -&gt; `...70`\n• `` -&gt; `...71`\n• `` -&gt; `...72`\n• `` -&gt; `...73`\n• `` -&gt; `...74`\n• `` -&gt; `...75`\n• `` -&gt; `...76`\n• `` -&gt; `...77`\n• `` -&gt; `...78`\n• `` -&gt; `...79`\n• `` -&gt; `...80`\n• `` -&gt; `...81`\n• `` -&gt; `...82`\n• `` -&gt; `...83`\n• `` -&gt; `...84`\n• `` -&gt; `...85`\n• `` -&gt; `...86`\n• `` -&gt; `...87`\n• `` -&gt; `...88`\n• `` -&gt; `...89`\n• `` -&gt; `...90`\n• `` -&gt; `...91`\n• `` -&gt; `...92`\n• `` -&gt; `...93`\n• `` -&gt; `...94`\n• `` -&gt; `...95`\n• `` -&gt; `...96`\n• `` -&gt; `...97`\n• `` -&gt; `...98`\n• `` -&gt; `...99`\n• `` -&gt; `...100`\n• `` -&gt; `...101`\n• `` -&gt; `...102`\n• `` -&gt; `...103`\n• `` -&gt; `...104`\n• `` -&gt; `...105`\n• `` -&gt; `...106`\n• `` -&gt; `...107`\n• `` -&gt; `...108`\n• `` -&gt; `...109`\n• `` -&gt; `...110`\n• `` -&gt; `...111`\n• `` -&gt; `...112`\n• `` -&gt; `...113`\n• `` -&gt; `...114`\n• `` -&gt; `...115`\n• `` -&gt; `...116`\n• `` -&gt; `...117`\n• `` -&gt; `...118`\n• `` -&gt; `...119`\n• `` -&gt; `...120`\n• `` -&gt; `...121`\n• `` -&gt; `...122`\n• `` -&gt; `...123`\n• `` -&gt; `...124`\n• `` -&gt; `...125`\n• `` -&gt; `...126`\n• `` -&gt; `...127`\n• `` -&gt; `...128`\n• `` -&gt; `...129`\n• `` -&gt; `...130`\n• `` -&gt; `...131`\n• `` -&gt; `...132`\n• `` -&gt; `...133`\n• `` -&gt; `...134`\n• `` -&gt; `...135`\n• `` -&gt; `...136`\n• `` -&gt; `...137`\n• `` -&gt; `...138`\n• `` -&gt; `...139`\n• `` -&gt; `...140`\n• `` -&gt; `...141`\n• `` -&gt; `...142`\n• `` -&gt; `...143`\n• `` -&gt; `...144`\n• `` -&gt; `...145`\n• `` -&gt; `...146`\n• `` -&gt; `...147`\n• `` -&gt; `...148`\n• `` -&gt; `...149`\n• `` -&gt; `...150`\n• `` -&gt; `...151`\n• `` -&gt; `...152`\n• `` -&gt; `...153`\n• `` -&gt; `...154`\n• `` -&gt; `...155`\n• `` -&gt; `...156`\n• `` -&gt; `...157`\n• `` -&gt; `...158`\n• `` -&gt; `...159`\n• `` -&gt; `...160`\n• `` -&gt; `...161`\n• `` -&gt; `...162`\n• `` -&gt; `...163`\n• `` -&gt; `...164`\n• `` -&gt; `...165`\n• `` -&gt; `...166`\n• `` -&gt; `...167`\n• `` -&gt; `...168`\n• `` -&gt; `...169`\n• `` -&gt; `...170`\n• `` -&gt; `...171`\n• `` -&gt; `...172`\n• `` -&gt; `...173`\n• `` -&gt; `...174`\n• `` -&gt; `...175`\n• `` -&gt; `...176`\n• `` -&gt; `...177`\n• `` -&gt; `...178`\n• `` -&gt; `...179`\n• `` -&gt; `...180`\n• `` -&gt; `...181`\n• `` -&gt; `...182`\n• `` -&gt; `...183`\n• `` -&gt; `...184`\n• `` -&gt; `...185`\n• `` -&gt; `...186`\n• `` -&gt; `...187`\n• `` -&gt; `...188`\n• `` -&gt; `...189`\n• `` -&gt; `...190`\n• `` -&gt; `...191`\n• `` -&gt; `...192`\n• `` -&gt; `...193`\n• `` -&gt; `...194`\n• `` -&gt; `...195`\n• `` -&gt; `...196`\n• `` -&gt; `...197`\n• `` -&gt; `...198`\n• `` -&gt; `...199`\n• `` -&gt; `...200`\n• `` -&gt; `...201`\n• `` -&gt; `...202`\n• `` -&gt; `...203`\n• `` -&gt; `...204`\n• `` -&gt; `...205`\n• `` -&gt; `...206`\n• `` -&gt; `...207`\n• `` -&gt; `...208`\n• `` -&gt; `...209`\n• `` -&gt; `...210`\n• `` -&gt; `...211`\n• `` -&gt; `...212`\n• `` -&gt; `...213`\n• `` -&gt; `...214`\n• `` -&gt; `...215`\n• `` -&gt; `...216`\n• `` -&gt; `...217`\n• `` -&gt; `...218`\n• `` -&gt; `...219`\n• `` -&gt; `...220`\n• `` -&gt; `...221`\n• `` -&gt; `...222`\n• `` -&gt; `...223`\n• `` -&gt; `...224`\n• `` -&gt; `...225`\n• `` -&gt; `...226`\n• `` -&gt; `...227`\n• `` -&gt; `...228`\n• `` -&gt; `...229`\n• `` -&gt; `...230`\n• `` -&gt; `...231`\n• `` -&gt; `...232`\n• `` -&gt; `...233`\n• `` -&gt; `...234`\n• `` -&gt; `...235`\n• `` -&gt; `...236`\n• `` -&gt; `...237`\n• `` -&gt; `...238`\n• `` -&gt; `...239`\n• `` -&gt; `...240`\n• `` -&gt; `...241`\n• `` -&gt; `...242`\n• `` -&gt; `...243`\n• `` -&gt; `...244`\n• `` -&gt; `...245`\n• `` -&gt; `...246`\n• `` -&gt; `...247`\n• `` -&gt; `...248`\n• `` -&gt; `...249`\n• `` -&gt; `...250`\n• `` -&gt; `...251`\n• `` -&gt; `...252`\n• `` -&gt; `...253`\n• `` -&gt; `...254`\n• `` -&gt; `...255`\n• `` -&gt; `...256`\n• `` -&gt; `...257`\n• `` -&gt; `...258`\n• `` -&gt; `...259`\n• `` -&gt; `...260`\n• `` -&gt; `...261`\n• `` -&gt; `...262`\n• `` -&gt; `...263`\n• `` -&gt; `...264`\n• `` -&gt; `...265`\n• `` -&gt; `...266`\n\nhead(re_exports,1)\n\n# A tibble: 1 × 266\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 253 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;, ...26 &lt;chr&gt;, ...27 &lt;chr&gt;,\n#   ...28 &lt;chr&gt;, ...29 &lt;chr&gt;, ...30 &lt;chr&gt;, ...31 &lt;chr&gt;, ...32 &lt;chr&gt;,\n#   ...33 &lt;chr&gt;, ...34 &lt;chr&gt;, ...35 &lt;chr&gt;, ...36 &lt;chr&gt;, ...37 &lt;chr&gt;,\n#   ...38 &lt;chr&gt;, ...39 &lt;chr&gt;, ...40 &lt;chr&gt;, ...41 &lt;chr&gt;, ...42 &lt;chr&gt;,\n#   ...43 &lt;chr&gt;, ...44 &lt;chr&gt;, ...45 &lt;chr&gt;, ...46 &lt;chr&gt;, ...47 &lt;chr&gt;, …"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "title": "Take-home Exercise 2",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n2.3.1 Processing Imports Data\nLet us have a quick glance of the dataframe using the code below.\n\ntibble(imports)\n\n# A tibble: 187 × 266\n   ...1  ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 Them… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 2 Subj… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 3 Topi… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 4 Tabl… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 5 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 6 Data… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 7 Sour… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 8 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n 9 &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n10 Data… 2025… 2024… 2024… 2024… 2024… 2024… 2024… 2024… 2024… 2024… 2024… 2024…\n# ℹ 177 more rows\n# ℹ 253 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;, ...26 &lt;chr&gt;, ...27 &lt;chr&gt;,\n#   ...28 &lt;chr&gt;, ...29 &lt;chr&gt;, ...30 &lt;chr&gt;, ...31 &lt;chr&gt;, ...32 &lt;chr&gt;,\n#   ...33 &lt;chr&gt;, ...34 &lt;chr&gt;, ...35 &lt;chr&gt;, ...36 &lt;chr&gt;, ...37 &lt;chr&gt;,\n#   ...38 &lt;chr&gt;, ...39 &lt;chr&gt;, ...40 &lt;chr&gt;, ...41 &lt;chr&gt;, ...42 &lt;chr&gt;, …\n\n\nFor more enhanced analysis, let us split the dataframe into 2, by continent and by country\n\nCountry LevelContinent Level\n\n\nThe code below will remove unwanted rows and only take the necessary rows.\n\nimports_country &lt;- imports[-c(1:9, 11, 12, 43, 85, 121, 136, 171:187), ]\n\nAfter the row selection, make the first row as the column headers.\n\ncolnames(imports_country) &lt;- imports_country[1, ]\nimports_country &lt;- imports_country[-1, ]\n\nPivot the dataframe using the code chunk below.\n\nimports_country &lt;- imports_country %&gt;% \n  pivot_longer(cols = -1, names_to = \"Date\", values_to = \"Value\") %&gt;% \n  pivot_wider(names_from = colnames(imports_country)[1], values_from = \"Value\")\n\nFormat the date column into yearmonth format using the code below.\n\nimports_country$`Date` &lt;- ym(\n  imports_country$`Date`\n)\n\nAs the trade values are numeric data, convert all columns except the date column into numeric data type.\n\nimports_country &lt;- imports_country %&gt;%\n  mutate(\n    across(-Date, as.numeric)\n  )\n\nExtract the year using the code below.\n\nimports_country &lt;- imports_country %&gt;% \n  mutate(Year = year(Date))\n\nReorder the columns to improve readability of the dataframe\n\nimports_country &lt;- imports_country %&gt;% \n  select(Year, everything(), -Date)\n\nNext, group the dataset based on the year and sum the trade values for each country.\n\nimports_country &lt;- imports_country %&gt;% \n  group_by(Year) %&gt;%\n  summarise(across(where(is.numeric), sum, na.rm = TRUE))\n\nAs the format for all 3 dataframes are the same, the same steps will be applied to all dataframes, divided into 2 levels, continent level and country level.\n\n\n\nimports_continent &lt;- imports[c(10, 12, 43, 85, 121, 136), ]\n\n\ncolnames(imports_continent) &lt;- imports_continent[1, ]\nimports_continent &lt;- imports_continent[-1, ]\n\n\nimports_continent &lt;- imports_continent %&gt;% \n  pivot_longer(cols = -1, names_to = \"Date\", values_to = \"Value\") %&gt;% \n  pivot_wider(names_from = colnames(imports_continent)[1], values_from = \"Value\")\n\n\nimports_continent$`Date` &lt;- ym(\n  imports_continent$`Date`\n)\n\n\nimports_continent &lt;- imports_continent %&gt;%\n  mutate(\n    across(-Date, as.numeric)\n  )\n\n\nimports_month &lt;- imports_continent %&gt;% \n  select(everything())\n\n\nimports_month &lt;- imports_continent %&gt;% \n  select(everything()) %&gt;% \n  mutate(\n    across(-Date, as.numeric)\n  )\n\n\nimports_continent &lt;- imports_continent %&gt;%\n  mutate(\n    across(-Date, as.numeric)\n  )\n\n\nimports_continent &lt;- imports_continent %&gt;% \n  mutate(Year = year(Date))\n\n\nimports_continent &lt;- imports_continent %&gt;% \n  select(Year, everything(), -Date)\n\n\nimports_continent &lt;- imports_continent %&gt;% \n  group_by(Year) %&gt;%\n  summarise(across(where(is.numeric), sum, na.rm = TRUE))\n\n\n\n\n\n\n2.3.2 Processing Domestic Exports Data\nLet us apply the same steps to both domestic exports and re-exports dataframe\n\nCountry LevelContinent Level\n\n\n\ndomexp_country &lt;- dom_exports[-c(1:9, 11, 12, 43, 85, 121, 136, 171:191), ]\n\n\ncolnames(domexp_country) &lt;- domexp_country[1, ]\ndomexp_country &lt;- domexp_country[-1, ]\n\n\ndomexp_country &lt;- domexp_country %&gt;% \n  pivot_longer(cols = -1, names_to = \"Date\", values_to = \"Value\") %&gt;% \n  pivot_wider(names_from = colnames(domexp_country)[1], values_from = \"Value\")\n\n\ndomexp_country$`Date` &lt;- ym(\n  domexp_country$`Date`\n)\n\n\ndomexp_country &lt;- domexp_country %&gt;%\n  mutate(\n    across(-Date, as.numeric)\n  )\n\n\ndomexp_country &lt;- domexp_country %&gt;% \n  mutate(Year = year(Date))\n\n\ndomexp_country &lt;- domexp_country %&gt;% \n  select(Year, everything(), -Date)\n\n\ndomexp_country &lt;- domexp_country %&gt;% \n  group_by(Year) %&gt;%\n  summarise(across(where(is.numeric), sum, na.rm = TRUE))\n\n\n\n\ndomexp_continent &lt;- dom_exports[c(10, 12, 43, 85, 121, 136), ]\n\n\ncolnames(domexp_continent) &lt;- domexp_continent[1, ]\ndomexp_continent &lt;- domexp_continent[-1, ]\n\n\ndomexp_continent &lt;- domexp_continent %&gt;% \n  pivot_longer(cols = -1, names_to = \"Date\", values_to = \"Value\") %&gt;% \n  pivot_wider(names_from = colnames(domexp_continent)[1], values_from = \"Value\")\n\n\ndomexp_continent$`Date` &lt;- ym(\n  domexp_continent$`Date`\n)\n\n\ndomexp_month &lt;- domexp_continent %&gt;% \n  select(everything()) %&gt;% \n  mutate(\n    across(-Date, as.numeric)\n  )\n\n\ndomexp_continent &lt;- domexp_continent %&gt;%\n  mutate(\n    across(-Date, as.numeric)\n  )\n\n\ndomexp_continent &lt;- domexp_continent %&gt;% \n  mutate(Year = year(Date))\n\n\ndomexp_continent &lt;- domexp_continent %&gt;% \n  select(Year, everything(), -Date)\n\n\ndomexp_continent &lt;- domexp_continent %&gt;% \n  group_by(Year) %&gt;%\n  summarise(across(where(is.numeric), sum, na.rm = TRUE))\n\n\n\n\n\n\n2.3.3 Processing Re-Exports Data\n\nCountry LevelContinent Level\n\n\n\nreexp_country &lt;- re_exports[-c(1:9, 11, 12, 43, 85, 121, 136, 171:191), ]\n\n\ncolnames(reexp_country) &lt;- reexp_country[1, ]\nreexp_country &lt;- reexp_country[-1, ]\n\n\nreexp_country &lt;- reexp_country %&gt;% \n  pivot_longer(cols = -1, names_to = \"Date\", values_to = \"Value\") %&gt;% \n  pivot_wider(names_from = colnames(reexp_country)[1], values_from = \"Value\")\n\n\nreexp_country$`Date` &lt;- ym(\n  reexp_country$`Date`\n)\n\n\nreexp_country &lt;- reexp_country %&gt;%\n  mutate(\n    across(-Date, as.numeric)\n  )\n\n\nreexp_country &lt;- reexp_country %&gt;% \n  mutate(Year = year(Date))\n\n\nreexp_country &lt;- reexp_country %&gt;% \n  select(Year, everything(), -Date)\n\n\nreexp_country &lt;- reexp_country %&gt;% \n  group_by(Year) %&gt;%\n  summarise(across(where(is.numeric), sum, na.rm = TRUE))\n\n\n\n\nreexp_continent &lt;- re_exports[c(10, 12, 43, 85, 121, 136), ]\n\n\ncolnames(reexp_continent) &lt;- reexp_continent[1, ]\nreexp_continent &lt;- reexp_continent[-1, ]\n\n\nreexp_continent &lt;- reexp_continent %&gt;% \n  pivot_longer(cols = -1, names_to = \"Date\", values_to = \"Value\") %&gt;% \n  pivot_wider(names_from = colnames(reexp_continent)[1], values_from = \"Value\")\n\n\nreexp_continent$`Date` &lt;- ym(\n  reexp_continent$`Date`\n)\n\n\nreexp_month &lt;- reexp_continent %&gt;% \n  select(everything())\n\n\nreexp_month &lt;- reexp_continent %&gt;% \n  select(everything()) %&gt;% \n  mutate(\n    across(-Date, as.numeric)\n  )\n\n\nreexp_continent &lt;- reexp_continent %&gt;%\n  mutate(\n    across(-Date, as.numeric)\n  )\n\n\nreexp_continent &lt;- reexp_continent %&gt;% \n  mutate(Year = year(Date))\n\n\nreexp_continent &lt;- reexp_continent %&gt;% \n  select(Year, everything(), -Date)\n\n\nreexp_continent &lt;- reexp_continent %&gt;% \n  group_by(Year) %&gt;%\n  summarise(across(where(is.numeric), sum, na.rm = TRUE))\n\n\n\n\n\n\n2.3.4 Combining Domestic Exports and Re-Exports Data\nUsing the code chunk below, we will combine both domestic exports and re-exports data.\n\nCountryContinent\n\n\n\nexports_country &lt;- domexp_country + reexp_country\nexports_country$Year &lt;- domexp_country$Year\nexports_country &lt;- exports_country %&gt;% relocate(Year)\n\n\n\n\nexports_continent &lt;- domexp_continent + reexp_continent\nexports_continent$Year &lt;- domexp_continent$Year\nexports_continent &lt;- exports_continent %&gt;% relocate(Year)\n\n\nexports_month &lt;- domexp_month\nexports_month[, c(2:6)] &lt;- domexp_month[, c(2:6)] + reexp_month[, c(2:6)]\n\n\n\n\n\n\n2.3.5 Joining Import and Export Data\nIn this section, we will expand the dataset and combine both imports and exports as the summary of merchandise trade.\n\nCountry LevelContinent Level\n\n\n\nexports_country &lt;- exports_country %&gt;% mutate(Type = \"Exports\")\nimports_country &lt;- imports_country %&gt;% mutate(Type = \"Imports\")\n\n\ntrade_country &lt;- bind_rows(exports_country, imports_country)\n\n\ntrade_country &lt;- trade_country %&gt;% arrange(Year)\n\n\ntrade_country &lt;- trade_country %&gt;% select(Year, Type, everything())\n\n\n\n\nexports_continent &lt;- exports_continent %&gt;% mutate(Type = \"Exports\")\nimports_continent &lt;- imports_continent %&gt;% mutate(Type = \"Imports\")\n\n\ntrade_continent &lt;- bind_rows(exports_continent, imports_continent)\n\n\ntrade_continent &lt;- trade_continent %&gt;% arrange(Year)\n\n\ntrade_continent &lt;- trade_continent %&gt;% select(Year, Type, everything())\n\n\ntrade_continent[,-c(1,2)] &lt;- trade_continent[,-c(1,2)] / 1000\n\n\nexports_month &lt;- exports_month %&gt;% mutate(Type = \"Exports\")\nimports_month &lt;- imports_month %&gt;% mutate(Type = \"Imports\")\n\n\ntrade_month &lt;- bind_rows(exports_month, imports_month)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#save-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#save-data",
    "title": "Take-home Exercise 2",
    "section": "2.4 Save Data",
    "text": "2.4 Save Data\nFor easier usage of cleaned dataframe, let us save it to csv file and load it to R environment\n\nwrite.csv(trade_country, \"data/trade_country.csv\", row.names = FALSE)\nwrite.csv(trade_continent, \"data/trade_continent.csv\", row.names = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#load-final-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#load-final-data",
    "title": "Take-home Exercise 2",
    "section": "2.5 Load Final Data",
    "text": "2.5 Load Final Data\nFinally, use the code below to load the final dataframe to R environment\n\ntrade_country &lt;- read_csv(\"data/trade_country.csv\")\n\nRows: 46 Columns: 156\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (1): Type\ndbl (155): Year, Antigua And Barbuda, Argentina, Bahamas, Bermuda, Brazil, C...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ntrade_continent &lt;- read_csv(\"data/trade_continent.csv\")\n\nRows: 46 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Type\ndbl (6): Year, America, Asia, Europe, Oceania, Africa\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualisation-make-overs",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualisation-make-overs",
    "title": "Take-home Exercise 2",
    "section": "3.1 Visualisation Make-Overs",
    "text": "3.1 Visualisation Make-Overs\nLet us begin this section with the pros and cons of 3 visualisations.\n\n3.1.1 Total Merchandise Trade at Current Price, 2020-2024\nLet us take a look at the first visualization for total merchandise trade in 2020-2024.\n\nOriginalVisual Make-Over\n\n\nThe figure below is showing the total merchandise trade comparison for each year from 2020-2024. What could be improved from this data visualisation?\n\nPros:\n\nThe visual design of the horizontal bar chart fits the theme of the data presented, which helps audience understand the context efficiently\nThe data is sorted in descending order based on the year, showing the latest year data on top of the chart, which allows audience to view the most recent information first\n\nCons:\n\nThe purpose of this chart is to compare the import and export of each year stated. However, the bar chart spacing does not indicate this comparison. To properly show the comparison, it should be visualized as clustered bar chart, where there is extra spacing for different years\nAlthough the choice of color palette is aesthetically nice, the color for all “imports” and all “exports” should be consistent and the legend should be shown in the chart. The current color does not highlight the difference between import and export as it is the same color with different opacity level\n\n\n\n\ntrade_summary &lt;- trade_continent %&gt;%\n  filter(Year &gt;= 2020 & Year &lt;= 2024) %&gt;%  \n  group_by(Year, Type) %&gt;%\n  summarise(Total = sum(America, Asia, Europe, Oceania, Africa, na.rm = TRUE), .groups = \"drop\")\n\ntrade_summary$Year &lt;- factor(trade_summary$Year, levels = sort(unique(trade_summary$Year), decreasing = FALSE))\n\nggplot(trade_summary, aes(y = Year, x = Total / 1000, fill = Type)) +  \n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.6), width = 0.5) +  \n  scale_fill_manual(values = c(\"Exports\" = \"skyblue\", \"Imports\" = \"lightcoral\")) + \n  labs(title = \"OVERALL EXPORTS AND IMPORTS OF SERVICES, 2020-2024\",\n       x = \"S$ Billion\", y = \"Year\") +\n  theme_minimal(base_size = 14) +  \n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 16), \n    legend.title = element_blank(),  \n    legend.position = \"bottom\",\n    plot.background = element_rect(fill = \"#E3ECF1\", color = NA)\n  ) +\n  geom_text(aes(label = round(Total / 1000, 1)), \n            position = position_dodge(width = 0.6), hjust = -0.3, size = 4, color = \"black\") +\n  geom_label(data = trade_summary %&gt;% group_by(Year) %&gt;%\n               summarise(Total = sum(Total) / 1000, .groups = \"drop\"), \n             aes(y = Year, x = 900,  \n                 label = paste0(\"Total: S$ \", round(Total, 1), \"B\")),\n             fill = \"white\", color = \"black\", fontface = \"bold\", size = 4, \n             label.size = 0.3, label.r = unit(5, \"pt\")) +\n  scale_x_continuous(limits = c(0, 1000),\n                     labels = scales::label_number())\n\n\n\n\n\n\n\n\nWhat are the key improvements on this visual?\n\nThe colors are standardized for both imports and exports, it ensures a clear definition of imports value and exports value.\nThe charts are clustered and grouped in years, showing a significant gap between every year’s data.\n\n\n\n\n\n\n3.1.2 Merchandise Trade Performance With Major Trading Partners, 2024\n\nOriginalVisual Make-Over\n\n\nThe figure below represents the total merchandise trade of the top 10 countries in 2024. Let us discuss the pros and cons of the visual shown below.\n\nPros:\n\nThe different bubble sizes that reflects the trade value with each country helps to highlight the countries with highest values more quickly.\nThe x-axis and y-axis range is symmetrical, showing accurate representations. Moreover, as the chart is diagonally split, it highlights whether the country has more export or import values.\n\nCons:\n\nThe placement of x-label and y-label is too close and can be misleading at first sight. For better visualisation, the label should be put at the other end of the line to avoid misinterpretations.\nThe color representing each country does not give any significant insight. Instead,\n\n\n\nBefore the make-over, let us do some data wrangling to match the original visualisation’s data structure. First, let us filter to 2024 data using the code below.\n\ntrade &lt;- trade_country %&gt;% filter(Year == 2024)\n\nAs the original visual shows the European Union, let us group all the countries that are part of the European Union.\n\neu_countries &lt;- c('Austria', 'Belgium', 'Bulgaria', 'Croatia', 'Cyprus',\n                  'Czech Rep', 'Denmark', 'Estonia', 'Finland', 'France',\n                  'Germany', 'Greece', 'Hungary', 'Ireland', 'Italy', 'Latvia',\n                  'Lithuania', 'Luxembourg', 'Malta', 'Netherlands', 'Poland',\n                  'Portugal', 'Romania', 'Slovakia', 'Slovenia', 'Spain', \n                  'Svalbard And Jan Mayen Islands','Sweden')\n\ntrade$EU &lt;- rowSums(trade[eu_countries])\n\nNow, let us pivot back the data and change the values from millions to billions using the code below.\n\ntrade &lt;- trade %&gt;%\n  pivot_longer(cols = -c(Year, Type), names_to = \"Country\", values_to = \"value\") %&gt;%\n  pivot_wider(names_from = Type, values_from = value) %&gt;% \n  mutate(\n    Imports = Imports/1000,\n    Exports = Exports/1000\n  )\n\nLet us define the color and the opacity of each country based on the imports or exports value. If exports value is higher, it will show green color, and blue if otherwise. The opacity represents how big the amount of the imports or exports in each country. The more solid the color, means the higher the trade value is.\n\ntrade &lt;- trade %&gt;%\n  mutate(\n    total_trade = Imports + Exports,\n    color = ifelse(Exports &gt; Imports, \n                   rgb(34/255, 139/255, 34/255, alpha = 1),\n                   rgb(70/255, 130/255, 180/255, alpha = 1)\n    ),\n    opacity = ifelse(Exports &gt; Imports, \n                 0.5 + (0.7 * Exports / max(Exports, na.rm = TRUE)),\n                 0.5 + (0.7 * Imports / max(Imports, na.rm = TRUE)))\n\n  )\n\n\ntrade &lt;- trade %&gt;% \n  arrange(desc(total_trade)) %&gt;% \n  slice_head(n = 10) \n\n\nggplot(trade, aes(x = Exports, y = Imports)) +\n    geom_tile(data = expand.grid(x = seq(0, 100, by = 0.5),  \n                             y = seq(0, 100, by = 0.5)), \n          aes(x = x, y = y, fill = x &gt; y), width = 0.5, height = 0.5, color = NA) +\n    scale_fill_manual(values = c(\n        \"TRUE\" = rgb(200/255, 255/255, 200/255, alpha = 0.2),\n        \"FALSE\" = rgb(173/255, 216/255, 230/255, alpha = 0.2)\n    )) +\n  \n    geom_point(aes(color = color, alpha = opacity), shape = 16, size = 5) +\n\n    geom_text(aes(label = paste(Country, \"\\n\", round(total_trade, 1))), \n              size = 4, color = \"black\", vjust = -0.5) +\n\n    geom_abline(intercept = 0, slope = 1, linetype = NA, size = 1) +\n    scale_x_continuous(limits = c(0, 100), breaks = seq(0, 100, 10), minor_breaks = NULL) +\n    scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, 10), minor_breaks = NULL) +\n    labs(x = \"Exports (S$ Billion)\", y = \"Imports (S$ Billion)\",\n         title = \"Merchandise Trade Performance With Major Trading Partners (2024)\") +\n    scale_color_identity() +\n    scale_alpha_continuous(range = c(0.1, 1)) +\n    theme_minimal() + \n    theme(\n        plot.title = element_text(hjust=0.5),\n        panel.grid.major = element_line(color = \"whitesmoke\", size = 0.4),\n        panel.grid.minor = element_blank(),\n        panel.background = element_rect(fill = \"transparent\", color = NA),\n        plot.background = element_rect(fill = \"transparent\", color = NA),\n        legend.position = \"none\"\n    )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: Removed 800 rows containing missing values or values outside the scale range\n(`geom_tile()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_segment()`).\n\n\n\n\n\n\n\n\n\nHow is this visual different from the original visualisation?\n\nInstead of representing each country with different colors, each dot color represents whether the exports or imports value dominates the overall trade value, where green represents exports and blue represents imports\nThe opacity level shows how big the amount of exports or imports with each trading partners.\nThe x-label and y-label is re-positioned to avoid misinterpretation of axis values.\n\n\n\n\n\n\n3.1.3 Non-Oil Domestic Exports (2024)\n\nOriginalVisual Make-Over\n\n\nNow let us have a look at the final visualisation, showing the non-oil domestic exports by major commodity sections in 2024. It shows the percentage of share of each non-oil goods trade category. Let us examine the pros and cons of the following visualisation.\n\nPros:\n\nThe visual above shows a detailed insight of each non-oil goods, showing both trade values and the percentage of share clearly.\nEach category is highlighted in different color palettes, highlighting different goods under non-oil category.\n\nCons:\n\nThe data is stacked into one bar. Although it visually fits the concept of the data presented, the data only shows the data for year 2024, hence, it will be better if it is separated into different bars for better readability.\nThe values are not sorted and it is uses both left and right side of the bar chart. It is not very efficient for readers as it may take sometime to figure out the category of each bar stack. It also can be misleading as the value is in random order.\n\n\n\n\n\n\n\n\n\nData Wrangling\n\n\n\n\n\nBefore showing the visual make-over, it is necessary to do some data wrangling as it is from different data source, which is the Merchandise Trade by Commodity Section (At Current Price), Monthly dataset. Let us prepare the data using the code below.\n\nnonoil &lt;- read_csv(\"data/nonoil.csv\")\n\nNew names:\nRows: 105 Columns: 734\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(734): ...1, ...2, ...3, ...4, ...5, ...6, ...7, ...8, ...9, ...10, ...1...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...12`\n• `` -&gt; `...13`\n• `` -&gt; `...14`\n• `` -&gt; `...15`\n• `` -&gt; `...16`\n• `` -&gt; `...17`\n• `` -&gt; `...18`\n• `` -&gt; `...19`\n• `` -&gt; `...20`\n• `` -&gt; `...21`\n• `` -&gt; `...22`\n• `` -&gt; `...23`\n• `` -&gt; `...24`\n• `` -&gt; `...25`\n• `` -&gt; `...26`\n• `` -&gt; `...27`\n• `` -&gt; `...28`\n• `` -&gt; `...29`\n• `` -&gt; `...30`\n• `` -&gt; `...31`\n• `` -&gt; `...32`\n• `` -&gt; `...33`\n• `` -&gt; `...34`\n• `` -&gt; `...35`\n• `` -&gt; `...36`\n• `` -&gt; `...37`\n• `` -&gt; `...38`\n• `` -&gt; `...39`\n• `` -&gt; `...40`\n• `` -&gt; `...41`\n• `` -&gt; `...42`\n• `` -&gt; `...43`\n• `` -&gt; `...44`\n• `` -&gt; `...45`\n• `` -&gt; `...46`\n• `` -&gt; `...47`\n• `` -&gt; `...48`\n• `` -&gt; `...49`\n• `` -&gt; `...50`\n• `` -&gt; `...51`\n• `` -&gt; `...52`\n• `` -&gt; `...53`\n• `` -&gt; `...54`\n• `` -&gt; `...55`\n• `` -&gt; `...56`\n• `` -&gt; `...57`\n• `` -&gt; `...58`\n• `` -&gt; `...59`\n• `` -&gt; `...60`\n• `` -&gt; `...61`\n• `` -&gt; `...62`\n• `` -&gt; `...63`\n• `` -&gt; `...64`\n• `` -&gt; `...65`\n• `` -&gt; `...66`\n• `` -&gt; `...67`\n• `` -&gt; `...68`\n• `` -&gt; `...69`\n• `` -&gt; `...70`\n• `` -&gt; `...71`\n• `` -&gt; `...72`\n• `` -&gt; `...73`\n• `` -&gt; `...74`\n• `` -&gt; `...75`\n• `` -&gt; `...76`\n• `` -&gt; `...77`\n• `` -&gt; `...78`\n• `` -&gt; `...79`\n• `` -&gt; `...80`\n• `` -&gt; `...81`\n• `` -&gt; `...82`\n• `` -&gt; `...83`\n• `` -&gt; `...84`\n• `` -&gt; `...85`\n• `` -&gt; `...86`\n• `` -&gt; `...87`\n• `` -&gt; `...88`\n• `` -&gt; `...89`\n• `` -&gt; `...90`\n• `` -&gt; `...91`\n• `` -&gt; `...92`\n• `` -&gt; `...93`\n• `` -&gt; `...94`\n• `` -&gt; `...95`\n• `` -&gt; `...96`\n• `` -&gt; `...97`\n• `` -&gt; `...98`\n• `` -&gt; `...99`\n• `` -&gt; `...100`\n• `` -&gt; `...101`\n• `` -&gt; `...102`\n• `` -&gt; `...103`\n• `` -&gt; `...104`\n• `` -&gt; `...105`\n• `` -&gt; `...106`\n• `` -&gt; `...107`\n• `` -&gt; `...108`\n• `` -&gt; `...109`\n• `` -&gt; `...110`\n• `` -&gt; `...111`\n• `` -&gt; `...112`\n• `` -&gt; `...113`\n• `` -&gt; `...114`\n• `` -&gt; `...115`\n• `` -&gt; `...116`\n• `` -&gt; `...117`\n• `` -&gt; `...118`\n• `` -&gt; `...119`\n• `` -&gt; `...120`\n• `` -&gt; `...121`\n• `` -&gt; `...122`\n• `` -&gt; `...123`\n• `` -&gt; `...124`\n• `` -&gt; `...125`\n• `` -&gt; `...126`\n• `` -&gt; `...127`\n• `` -&gt; `...128`\n• `` -&gt; `...129`\n• `` -&gt; `...130`\n• `` -&gt; `...131`\n• `` -&gt; `...132`\n• `` -&gt; `...133`\n• `` -&gt; `...134`\n• `` -&gt; `...135`\n• `` -&gt; `...136`\n• `` -&gt; `...137`\n• `` -&gt; `...138`\n• `` -&gt; `...139`\n• `` -&gt; `...140`\n• `` -&gt; `...141`\n• `` -&gt; `...142`\n• `` -&gt; `...143`\n• `` -&gt; `...144`\n• `` -&gt; `...145`\n• `` -&gt; `...146`\n• `` -&gt; `...147`\n• `` -&gt; `...148`\n• `` -&gt; `...149`\n• `` -&gt; `...150`\n• `` -&gt; `...151`\n• `` -&gt; `...152`\n• `` -&gt; `...153`\n• `` -&gt; `...154`\n• `` -&gt; `...155`\n• `` -&gt; `...156`\n• `` -&gt; `...157`\n• `` -&gt; `...158`\n• `` -&gt; `...159`\n• `` -&gt; `...160`\n• `` -&gt; `...161`\n• `` -&gt; `...162`\n• `` -&gt; `...163`\n• `` -&gt; `...164`\n• `` -&gt; `...165`\n• `` -&gt; `...166`\n• `` -&gt; `...167`\n• `` -&gt; `...168`\n• `` -&gt; `...169`\n• `` -&gt; `...170`\n• `` -&gt; `...171`\n• `` -&gt; `...172`\n• `` -&gt; `...173`\n• `` -&gt; `...174`\n• `` -&gt; `...175`\n• `` -&gt; `...176`\n• `` -&gt; `...177`\n• `` -&gt; `...178`\n• `` -&gt; `...179`\n• `` -&gt; `...180`\n• `` -&gt; `...181`\n• `` -&gt; `...182`\n• `` -&gt; `...183`\n• `` -&gt; `...184`\n• `` -&gt; `...185`\n• `` -&gt; `...186`\n• `` -&gt; `...187`\n• `` -&gt; `...188`\n• `` -&gt; `...189`\n• `` -&gt; `...190`\n• `` -&gt; `...191`\n• `` -&gt; `...192`\n• `` -&gt; `...193`\n• `` -&gt; `...194`\n• `` -&gt; `...195`\n• `` -&gt; `...196`\n• `` -&gt; `...197`\n• `` -&gt; `...198`\n• `` -&gt; `...199`\n• `` -&gt; `...200`\n• `` -&gt; `...201`\n• `` -&gt; `...202`\n• `` -&gt; `...203`\n• `` -&gt; `...204`\n• `` -&gt; `...205`\n• `` -&gt; `...206`\n• `` -&gt; `...207`\n• `` -&gt; `...208`\n• `` -&gt; `...209`\n• `` -&gt; `...210`\n• `` -&gt; `...211`\n• `` -&gt; `...212`\n• `` -&gt; `...213`\n• `` -&gt; `...214`\n• `` -&gt; `...215`\n• `` -&gt; `...216`\n• `` -&gt; `...217`\n• `` -&gt; `...218`\n• `` -&gt; `...219`\n• `` -&gt; `...220`\n• `` -&gt; `...221`\n• `` -&gt; `...222`\n• `` -&gt; `...223`\n• `` -&gt; `...224`\n• `` -&gt; `...225`\n• `` -&gt; `...226`\n• `` -&gt; `...227`\n• `` -&gt; `...228`\n• `` -&gt; `...229`\n• `` -&gt; `...230`\n• `` -&gt; `...231`\n• `` -&gt; `...232`\n• `` -&gt; `...233`\n• `` -&gt; `...234`\n• `` -&gt; `...235`\n• `` -&gt; `...236`\n• `` -&gt; `...237`\n• `` -&gt; `...238`\n• `` -&gt; `...239`\n• `` -&gt; `...240`\n• `` -&gt; `...241`\n• `` -&gt; `...242`\n• `` -&gt; `...243`\n• `` -&gt; `...244`\n• `` -&gt; `...245`\n• `` -&gt; `...246`\n• `` -&gt; `...247`\n• `` -&gt; `...248`\n• `` -&gt; `...249`\n• `` -&gt; `...250`\n• `` -&gt; `...251`\n• `` -&gt; `...252`\n• `` -&gt; `...253`\n• `` -&gt; `...254`\n• `` -&gt; `...255`\n• `` -&gt; `...256`\n• `` -&gt; `...257`\n• `` -&gt; `...258`\n• `` -&gt; `...259`\n• `` -&gt; `...260`\n• `` -&gt; `...261`\n• `` -&gt; `...262`\n• `` -&gt; `...263`\n• `` -&gt; `...264`\n• `` -&gt; `...265`\n• `` -&gt; `...266`\n• `` -&gt; `...267`\n• `` -&gt; `...268`\n• `` -&gt; `...269`\n• `` -&gt; `...270`\n• `` -&gt; `...271`\n• `` -&gt; `...272`\n• `` -&gt; `...273`\n• `` -&gt; `...274`\n• `` -&gt; `...275`\n• `` -&gt; `...276`\n• `` -&gt; `...277`\n• `` -&gt; `...278`\n• `` -&gt; `...279`\n• `` -&gt; `...280`\n• `` -&gt; `...281`\n• `` -&gt; `...282`\n• `` -&gt; `...283`\n• `` -&gt; `...284`\n• `` -&gt; `...285`\n• `` -&gt; `...286`\n• `` -&gt; `...287`\n• `` -&gt; `...288`\n• `` -&gt; `...289`\n• `` -&gt; `...290`\n• `` -&gt; `...291`\n• `` -&gt; `...292`\n• `` -&gt; `...293`\n• `` -&gt; `...294`\n• `` -&gt; `...295`\n• `` -&gt; `...296`\n• `` -&gt; `...297`\n• `` -&gt; `...298`\n• `` -&gt; `...299`\n• `` -&gt; `...300`\n• `` -&gt; `...301`\n• `` -&gt; `...302`\n• `` -&gt; `...303`\n• `` -&gt; `...304`\n• `` -&gt; `...305`\n• `` -&gt; `...306`\n• `` -&gt; `...307`\n• `` -&gt; `...308`\n• `` -&gt; `...309`\n• `` -&gt; `...310`\n• `` -&gt; `...311`\n• `` -&gt; `...312`\n• `` -&gt; `...313`\n• `` -&gt; `...314`\n• `` -&gt; `...315`\n• `` -&gt; `...316`\n• `` -&gt; `...317`\n• `` -&gt; `...318`\n• `` -&gt; `...319`\n• `` -&gt; `...320`\n• `` -&gt; `...321`\n• `` -&gt; `...322`\n• `` -&gt; `...323`\n• `` -&gt; `...324`\n• `` -&gt; `...325`\n• `` -&gt; `...326`\n• `` -&gt; `...327`\n• `` -&gt; `...328`\n• `` -&gt; `...329`\n• `` -&gt; `...330`\n• `` -&gt; `...331`\n• `` -&gt; `...332`\n• `` -&gt; `...333`\n• `` -&gt; `...334`\n• `` -&gt; `...335`\n• `` -&gt; `...336`\n• `` -&gt; `...337`\n• `` -&gt; `...338`\n• `` -&gt; `...339`\n• `` -&gt; `...340`\n• `` -&gt; `...341`\n• `` -&gt; `...342`\n• `` -&gt; `...343`\n• `` -&gt; `...344`\n• `` -&gt; `...345`\n• `` -&gt; `...346`\n• `` -&gt; `...347`\n• `` -&gt; `...348`\n• `` -&gt; `...349`\n• `` -&gt; `...350`\n• `` -&gt; `...351`\n• `` -&gt; `...352`\n• `` -&gt; `...353`\n• `` -&gt; `...354`\n• `` -&gt; `...355`\n• `` -&gt; `...356`\n• `` -&gt; `...357`\n• `` -&gt; `...358`\n• `` -&gt; `...359`\n• `` -&gt; `...360`\n• `` -&gt; `...361`\n• `` -&gt; `...362`\n• `` -&gt; `...363`\n• `` -&gt; `...364`\n• `` -&gt; `...365`\n• `` -&gt; `...366`\n• `` -&gt; `...367`\n• `` -&gt; `...368`\n• `` -&gt; `...369`\n• `` -&gt; `...370`\n• `` -&gt; `...371`\n• `` -&gt; `...372`\n• `` -&gt; `...373`\n• `` -&gt; `...374`\n• `` -&gt; `...375`\n• `` -&gt; `...376`\n• `` -&gt; `...377`\n• `` -&gt; `...378`\n• `` -&gt; `...379`\n• `` -&gt; `...380`\n• `` -&gt; `...381`\n• `` -&gt; `...382`\n• `` -&gt; `...383`\n• `` -&gt; `...384`\n• `` -&gt; `...385`\n• `` -&gt; `...386`\n• `` -&gt; `...387`\n• `` -&gt; `...388`\n• `` -&gt; `...389`\n• `` -&gt; `...390`\n• `` -&gt; `...391`\n• `` -&gt; `...392`\n• `` -&gt; `...393`\n• `` -&gt; `...394`\n• `` -&gt; `...395`\n• `` -&gt; `...396`\n• `` -&gt; `...397`\n• `` -&gt; `...398`\n• `` -&gt; `...399`\n• `` -&gt; `...400`\n• `` -&gt; `...401`\n• `` -&gt; `...402`\n• `` -&gt; `...403`\n• `` -&gt; `...404`\n• `` -&gt; `...405`\n• `` -&gt; `...406`\n• `` -&gt; `...407`\n• `` -&gt; `...408`\n• `` -&gt; `...409`\n• `` -&gt; `...410`\n• `` -&gt; `...411`\n• `` -&gt; `...412`\n• `` -&gt; `...413`\n• `` -&gt; `...414`\n• `` -&gt; `...415`\n• `` -&gt; `...416`\n• `` -&gt; `...417`\n• `` -&gt; `...418`\n• `` -&gt; `...419`\n• `` -&gt; `...420`\n• `` -&gt; `...421`\n• `` -&gt; `...422`\n• `` -&gt; `...423`\n• `` -&gt; `...424`\n• `` -&gt; `...425`\n• `` -&gt; `...426`\n• `` -&gt; `...427`\n• `` -&gt; `...428`\n• `` -&gt; `...429`\n• `` -&gt; `...430`\n• `` -&gt; `...431`\n• `` -&gt; `...432`\n• `` -&gt; `...433`\n• `` -&gt; `...434`\n• `` -&gt; `...435`\n• `` -&gt; `...436`\n• `` -&gt; `...437`\n• `` -&gt; `...438`\n• `` -&gt; `...439`\n• `` -&gt; `...440`\n• `` -&gt; `...441`\n• `` -&gt; `...442`\n• `` -&gt; `...443`\n• `` -&gt; `...444`\n• `` -&gt; `...445`\n• `` -&gt; `...446`\n• `` -&gt; `...447`\n• `` -&gt; `...448`\n• `` -&gt; `...449`\n• `` -&gt; `...450`\n• `` -&gt; `...451`\n• `` -&gt; `...452`\n• `` -&gt; `...453`\n• `` -&gt; `...454`\n• `` -&gt; `...455`\n• `` -&gt; `...456`\n• `` -&gt; `...457`\n• `` -&gt; `...458`\n• `` -&gt; `...459`\n• `` -&gt; `...460`\n• `` -&gt; `...461`\n• `` -&gt; `...462`\n• `` -&gt; `...463`\n• `` -&gt; `...464`\n• `` -&gt; `...465`\n• `` -&gt; `...466`\n• `` -&gt; `...467`\n• `` -&gt; `...468`\n• `` -&gt; `...469`\n• `` -&gt; `...470`\n• `` -&gt; `...471`\n• `` -&gt; `...472`\n• `` -&gt; `...473`\n• `` -&gt; `...474`\n• `` -&gt; `...475`\n• `` -&gt; `...476`\n• `` -&gt; `...477`\n• `` -&gt; `...478`\n• `` -&gt; `...479`\n• `` -&gt; `...480`\n• `` -&gt; `...481`\n• `` -&gt; `...482`\n• `` -&gt; `...483`\n• `` -&gt; `...484`\n• `` -&gt; `...485`\n• `` -&gt; `...486`\n• `` -&gt; `...487`\n• `` -&gt; `...488`\n• `` -&gt; `...489`\n• `` -&gt; `...490`\n• `` -&gt; `...491`\n• `` -&gt; `...492`\n• `` -&gt; `...493`\n• `` -&gt; `...494`\n• `` -&gt; `...495`\n• `` -&gt; `...496`\n• `` -&gt; `...497`\n• `` -&gt; `...498`\n• `` -&gt; `...499`\n• `` -&gt; `...500`\n• `` -&gt; `...501`\n• `` -&gt; `...502`\n• `` -&gt; `...503`\n• `` -&gt; `...504`\n• `` -&gt; `...505`\n• `` -&gt; `...506`\n• `` -&gt; `...507`\n• `` -&gt; `...508`\n• `` -&gt; `...509`\n• `` -&gt; `...510`\n• `` -&gt; `...511`\n• `` -&gt; `...512`\n• `` -&gt; `...513`\n• `` -&gt; `...514`\n• `` -&gt; `...515`\n• `` -&gt; `...516`\n• `` -&gt; `...517`\n• `` -&gt; `...518`\n• `` -&gt; `...519`\n• `` -&gt; `...520`\n• `` -&gt; `...521`\n• `` -&gt; `...522`\n• `` -&gt; `...523`\n• `` -&gt; `...524`\n• `` -&gt; `...525`\n• `` -&gt; `...526`\n• `` -&gt; `...527`\n• `` -&gt; `...528`\n• `` -&gt; `...529`\n• `` -&gt; `...530`\n• `` -&gt; `...531`\n• `` -&gt; `...532`\n• `` -&gt; `...533`\n• `` -&gt; `...534`\n• `` -&gt; `...535`\n• `` -&gt; `...536`\n• `` -&gt; `...537`\n• `` -&gt; `...538`\n• `` -&gt; `...539`\n• `` -&gt; `...540`\n• `` -&gt; `...541`\n• `` -&gt; `...542`\n• `` -&gt; `...543`\n• `` -&gt; `...544`\n• `` -&gt; `...545`\n• `` -&gt; `...546`\n• `` -&gt; `...547`\n• `` -&gt; `...548`\n• `` -&gt; `...549`\n• `` -&gt; `...550`\n• `` -&gt; `...551`\n• `` -&gt; `...552`\n• `` -&gt; `...553`\n• `` -&gt; `...554`\n• `` -&gt; `...555`\n• `` -&gt; `...556`\n• `` -&gt; `...557`\n• `` -&gt; `...558`\n• `` -&gt; `...559`\n• `` -&gt; `...560`\n• `` -&gt; `...561`\n• `` -&gt; `...562`\n• `` -&gt; `...563`\n• `` -&gt; `...564`\n• `` -&gt; `...565`\n• `` -&gt; `...566`\n• `` -&gt; `...567`\n• `` -&gt; `...568`\n• `` -&gt; `...569`\n• `` -&gt; `...570`\n• `` -&gt; `...571`\n• `` -&gt; `...572`\n• `` -&gt; `...573`\n• `` -&gt; `...574`\n• `` -&gt; `...575`\n• `` -&gt; `...576`\n• `` -&gt; `...577`\n• `` -&gt; `...578`\n• `` -&gt; `...579`\n• `` -&gt; `...580`\n• `` -&gt; `...581`\n• `` -&gt; `...582`\n• `` -&gt; `...583`\n• `` -&gt; `...584`\n• `` -&gt; `...585`\n• `` -&gt; `...586`\n• `` -&gt; `...587`\n• `` -&gt; `...588`\n• `` -&gt; `...589`\n• `` -&gt; `...590`\n• `` -&gt; `...591`\n• `` -&gt; `...592`\n• `` -&gt; `...593`\n• `` -&gt; `...594`\n• `` -&gt; `...595`\n• `` -&gt; `...596`\n• `` -&gt; `...597`\n• `` -&gt; `...598`\n• `` -&gt; `...599`\n• `` -&gt; `...600`\n• `` -&gt; `...601`\n• `` -&gt; `...602`\n• `` -&gt; `...603`\n• `` -&gt; `...604`\n• `` -&gt; `...605`\n• `` -&gt; `...606`\n• `` -&gt; `...607`\n• `` -&gt; `...608`\n• `` -&gt; `...609`\n• `` -&gt; `...610`\n• `` -&gt; `...611`\n• `` -&gt; `...612`\n• `` -&gt; `...613`\n• `` -&gt; `...614`\n• `` -&gt; `...615`\n• `` -&gt; `...616`\n• `` -&gt; `...617`\n• `` -&gt; `...618`\n• `` -&gt; `...619`\n• `` -&gt; `...620`\n• `` -&gt; `...621`\n• `` -&gt; `...622`\n• `` -&gt; `...623`\n• `` -&gt; `...624`\n• `` -&gt; `...625`\n• `` -&gt; `...626`\n• `` -&gt; `...627`\n• `` -&gt; `...628`\n• `` -&gt; `...629`\n• `` -&gt; `...630`\n• `` -&gt; `...631`\n• `` -&gt; `...632`\n• `` -&gt; `...633`\n• `` -&gt; `...634`\n• `` -&gt; `...635`\n• `` -&gt; `...636`\n• `` -&gt; `...637`\n• `` -&gt; `...638`\n• `` -&gt; `...639`\n• `` -&gt; `...640`\n• `` -&gt; `...641`\n• `` -&gt; `...642`\n• `` -&gt; `...643`\n• `` -&gt; `...644`\n• `` -&gt; `...645`\n• `` -&gt; `...646`\n• `` -&gt; `...647`\n• `` -&gt; `...648`\n• `` -&gt; `...649`\n• `` -&gt; `...650`\n• `` -&gt; `...651`\n• `` -&gt; `...652`\n• `` -&gt; `...653`\n• `` -&gt; `...654`\n• `` -&gt; `...655`\n• `` -&gt; `...656`\n• `` -&gt; `...657`\n• `` -&gt; `...658`\n• `` -&gt; `...659`\n• `` -&gt; `...660`\n• `` -&gt; `...661`\n• `` -&gt; `...662`\n• `` -&gt; `...663`\n• `` -&gt; `...664`\n• `` -&gt; `...665`\n• `` -&gt; `...666`\n• `` -&gt; `...667`\n• `` -&gt; `...668`\n• `` -&gt; `...669`\n• `` -&gt; `...670`\n• `` -&gt; `...671`\n• `` -&gt; `...672`\n• `` -&gt; `...673`\n• `` -&gt; `...674`\n• `` -&gt; `...675`\n• `` -&gt; `...676`\n• `` -&gt; `...677`\n• `` -&gt; `...678`\n• `` -&gt; `...679`\n• `` -&gt; `...680`\n• `` -&gt; `...681`\n• `` -&gt; `...682`\n• `` -&gt; `...683`\n• `` -&gt; `...684`\n• `` -&gt; `...685`\n• `` -&gt; `...686`\n• `` -&gt; `...687`\n• `` -&gt; `...688`\n• `` -&gt; `...689`\n• `` -&gt; `...690`\n• `` -&gt; `...691`\n• `` -&gt; `...692`\n• `` -&gt; `...693`\n• `` -&gt; `...694`\n• `` -&gt; `...695`\n• `` -&gt; `...696`\n• `` -&gt; `...697`\n• `` -&gt; `...698`\n• `` -&gt; `...699`\n• `` -&gt; `...700`\n• `` -&gt; `...701`\n• `` -&gt; `...702`\n• `` -&gt; `...703`\n• `` -&gt; `...704`\n• `` -&gt; `...705`\n• `` -&gt; `...706`\n• `` -&gt; `...707`\n• `` -&gt; `...708`\n• `` -&gt; `...709`\n• `` -&gt; `...710`\n• `` -&gt; `...711`\n• `` -&gt; `...712`\n• `` -&gt; `...713`\n• `` -&gt; `...714`\n• `` -&gt; `...715`\n• `` -&gt; `...716`\n• `` -&gt; `...717`\n• `` -&gt; `...718`\n• `` -&gt; `...719`\n• `` -&gt; `...720`\n• `` -&gt; `...721`\n• `` -&gt; `...722`\n• `` -&gt; `...723`\n• `` -&gt; `...724`\n• `` -&gt; `...725`\n• `` -&gt; `...726`\n• `` -&gt; `...727`\n• `` -&gt; `...728`\n• `` -&gt; `...729`\n• `` -&gt; `...730`\n• `` -&gt; `...731`\n• `` -&gt; `...732`\n• `` -&gt; `...733`\n• `` -&gt; `...734`\n\nhead(nonoil,1)\n\n# A tibble: 1 × 734\n  ...1   ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12 ...13\n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 Theme… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 721 more variables: ...14 &lt;chr&gt;, ...15 &lt;chr&gt;, ...16 &lt;chr&gt;, ...17 &lt;chr&gt;,\n#   ...18 &lt;chr&gt;, ...19 &lt;chr&gt;, ...20 &lt;chr&gt;, ...21 &lt;chr&gt;, ...22 &lt;chr&gt;,\n#   ...23 &lt;chr&gt;, ...24 &lt;chr&gt;, ...25 &lt;chr&gt;, ...26 &lt;chr&gt;, ...27 &lt;chr&gt;,\n#   ...28 &lt;chr&gt;, ...29 &lt;chr&gt;, ...30 &lt;chr&gt;, ...31 &lt;chr&gt;, ...32 &lt;chr&gt;,\n#   ...33 &lt;chr&gt;, ...34 &lt;chr&gt;, ...35 &lt;chr&gt;, ...36 &lt;chr&gt;, ...37 &lt;chr&gt;,\n#   ...38 &lt;chr&gt;, ...39 &lt;chr&gt;, ...40 &lt;chr&gt;, ...41 &lt;chr&gt;, ...42 &lt;chr&gt;,\n#   ...43 &lt;chr&gt;, ...44 &lt;chr&gt;, ...45 &lt;chr&gt;, ...46 &lt;chr&gt;, ...47 &lt;chr&gt;, …\n\n\n\nnonoil &lt;- nonoil[c(10, 57:65), ]\n\n\ncolnames(nonoil) &lt;- nonoil[1, ]\nnonoil &lt;- nonoil[-1, ]\n\n\nnonoil &lt;- nonoil[, -c(2, 15:ncol(nonoil))]\n\n\nnonoil[,2:13] &lt;- lapply(nonoil[,2:13], as.numeric)\n\n\nnonoil$Total &lt;- rowSums(nonoil[, 2:13])\n\n\nnonoil &lt;- nonoil %&gt;% \n  rename(Category = `Data Series`)\n\n\nnonoil &lt;- nonoil %&gt;% \n  select(Category, Total)\n\n\nnonoil &lt;- nonoil %&gt;% \n  mutate(Total = round(Total/1000000, 1))\n\n\n\n\n\nnonoil &lt;- nonoil %&gt;%\n  mutate(Percentage = Total / sum(Total) * 100)\n\ntotal_value &lt;- sum(nonoil$Total)\n\nggplot(nonoil, aes(x = reorder(Category, Total), y = Total)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(aes(label = paste0(Total, \" (\", round(Percentage, 1), \"%)\")),\n            hjust = -0.2, size = 3) +\n  ggtitle(\"Non-Oil Domestic Exports 2024\", paste(\"Total:\", \"S$\", total_value, \"Billion\")) +\n  scale_y_continuous(limits = c(0, 90)) +\n  coord_flip() +  \n  labs(x = \"Non-Oil Goods\", y = \"Total Value (S$ Billion)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n        plot.subtitle = element_text(hjust = 0.5, size = 12, face = \"bold\"),\n        axis.text.y = element_text(size = 8),\n        axis.title.x = element_text(face = \"bold\"),\n        axis.title.y = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\nWhat are the key improvements of the make-over visualisation?\n\nEach category is separated to different bar charts and no longer stacked, showing the value of each category efficiently and improves the readability.\nThe data is sorted from highest value to lowest value, highlighting the top non-oil category with highest trade value. Each category also shows the percentage, representing the share of each non-oil goods."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#time-series-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#time-series-analysis",
    "title": "Take-home Exercise 2",
    "section": "3.2 Time-Series Analysis",
    "text": "3.2 Time-Series Analysis\n\n3.2.1 Yearly Trade in Asia vs America\n\ntrade_asia &lt;- trade_continent %&gt;%\n  filter(between(Year, 2015, 2024)) %&gt;% \n  select(Year, Type, Asia)\n\nggplot(trade_asia, aes(x = Year, y = Asia, color = Type, group = Type)) +\n  geom_line(size = 1) +\n  geom_point(size = 3) +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  labs(title = \"Yearly Exports vs Imports in Asia\",\n       x = \"Year\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Trade Type\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n    legend.position = \"bottom\",\n    legend.justification = \"center\"\n  )\n\n\n\n\n\n\n\n\nFrom the figure above, we can see that in Asia, the exports value is always higher than the imports. The chart shows significant drop of value from when entering the year 2023. The pattern roughly shows there is a drop of trade value every 2-3 years.\n\ntrade_us &lt;- trade_continent %&gt;%\n  filter(between(Year, 2015, 2024)) %&gt;% \n  select(Year, Type, America)\n\nggplot(trade_us, aes(x = Year, y = America, color = Type, group = Type)) +\n  geom_line(size = 1) +\n  geom_point(size = 3) +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  labs(title = \"Yearly Exports vs Imports in America\",\n       x = \"Year\",\n       y = \"Trade Value (S$ Billion)\",\n       color = \"Trade Type\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n    legend.position = \"bottom\",\n    legend.justification = \"center\"\n  )\n\n\n\n\n\n\n\n\nHowever, it seems to be quite a different story for America side. The imports value is generally higher than exports, while the exports value has only been higher in the year 2020. This shows that Singapore did more imports than exports with America. The imports value spikes quite quickly from the year 2020 to 2022.\n\n\n3.2.2 Seasonal Plot Analysis\nLet us do some data wrangling to plot a seasonal plot. To begin the preparation, filter the date to analyse year 2020 to 2024.\n\ntotal_continent &lt;- trade_month %&gt;%\n  filter(between(Date, as.Date(\"2020-01-01\"), as.Date(\"2024-12-31\"))) %&gt;% \n  group_by(Date) %&gt;%\n  summarise(across(where(is.numeric), sum, na.rm = TRUE))\n\nCreate a new column “Month” to show the monthly seasonality.\n\ntotal_continent &lt;- total_continent %&gt;%\n  mutate(Month = yearmonth(Date)) %&gt;% \n  as_tsibble(index = Month)\n\n\ntotal_continent &lt;- total_continent %&gt;% \n  pivot_longer(cols = c(2:6),\n               names_to = \"Continent\",\n               values_to = \"Value\") %&gt;% \n  mutate(Value = Value/1000)\n\n\ntotal_continent %&gt;% \n  gg_season(Value, size = 0.8)\n\n\n\n\n\n\n\n\nInsights from Seasonal Plot:\n\nThe pattern for all 5 continents are quite similar. In all 5 continents, the trade value for year 2020 is relatively low.\nIn 2023, the trade value for all continents except for Africa, peaks around the month of March.\nThe highest trade value for all continents are in year in 2022 and 2024. Year 2022 is significantly higher in Asia, Europe and Oceania.\n\n\n\n3.2.3 Cycle Plot Analysis\nThe cycle plot below will show the pattern from year to year in each month. This plot will show whether there is repeated patterns in each month for every continent.\n\ntotal_continent %&gt;% \n  gg_subseries(Value)\n\n\n\n\n\n\n\n\nFrom the plot above, we can roughly see quite a similar pattern in each month. For all continents in 2022, the highest peak is in the month of August. In the month of February and March, the pattern tends to be more random as compared to other months."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-background",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-background",
    "title": "Take-home Exercise 1",
    "section": "1.1 The Background",
    "text": "1.1 The Background\nThe maritime industry plays a crucial role in supporting the global trade ecosystem, which serves as the primary mode for goods transportation. As it supports the international trading market, it is very important to pay more attention to the operational efficiency of the maritime industry. The purpose of this paper is to present the findings from shipping voyage data."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "title": "Take-home Exercise 1",
    "section": "1.2 The Data",
    "text": "1.2 The Data\nThe following are the details of the data source for this analysis:\n\nData Source: Ship Performance Clustering Dataset\nDataset Size: 18 columns x 2,736 rows\nData format: csv file"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task",
    "title": "Take-home Exercise 1",
    "section": "1.3 The Task",
    "text": "1.3 The Task\nAs the graphical editor of the media company, an article about ship performance in the Gulf of Guinea will be written and published. Hence, this paper will include the following contents:\n\nExploratory Data Analysis of ship performance based on different underlying factors\nVisualization of key operational metrics of the ship for future performance optimizations in the maritime industry"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-and-install-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-and-install-packages",
    "title": "Take-home Exercise 1",
    "section": "2.1 Load and Install Packages",
    "text": "2.1 Load and Install Packages\nFor this analysis, tidyverse and ggplot2 family packages will be used.\n\npacman::p_load(tidyverse, ggrepel, patchwork, ggthemes, hrbrthemes, ggiraph,\n               plotly, DT, readxl, gifski, gapminder, gganimate, ggdist, ggridges,\n               colorspace, ggstatsplot, crosstalk, FunnelPlotR, knitr, scales,\n               corrplot)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#import-data",
    "title": "Take-home Exercise 1",
    "section": "2.2 Import Data",
    "text": "2.2 Import Data\nImport ship performance dataset to get started with the analysis.\n\nship &lt;- read_csv(\"data/Ship.csv\")\n\nRows: 2736 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): Ship_Type, Route_Type, Engine_Type, Maintenance_Status, Weather_C...\ndbl  (12): Speed_Over_Ground_knots, Engine_Power_kW, Distance_Traveled_nm, D...\ndate  (1): Date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#select-variables",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#select-variables",
    "title": "Take-home Exercise 1",
    "section": "3.1 Select Variables",
    "text": "3.1 Select Variables\nBefore we begin with the analysis, let us do some variable analysis and check the columns that we will be using for this analysis. Each row of the dataset represents the performance metrics and attributes for a specific voyage/ship over a given timeframe.\n\ncolnames(ship)\n\n [1] \"Date\"                    \"Ship_Type\"              \n [3] \"Route_Type\"              \"Engine_Type\"            \n [5] \"Maintenance_Status\"      \"Speed_Over_Ground_knots\"\n [7] \"Engine_Power_kW\"         \"Distance_Traveled_nm\"   \n [9] \"Draft_meters\"            \"Weather_Condition\"      \n[11] \"Cargo_Weight_tons\"       \"Operational_Cost_USD\"   \n[13] \"Revenue_per_Voyage_USD\"  \"Turnaround_Time_hours\"  \n[15] \"Efficiency_nm_per_kWh\"   \"Seasonal_Impact_Score\"  \n[17] \"Weekly_Voyage_Count\"     \"Average_Load_Percentage\"\n\n\nFor easier read, let us list down all the columns in the table below to analyse the data types and the description.\n\nShip Dataframe\n\n\n\n\n\n\n\n\n\nColumn Name\nType\nDescription\n\n\n\n\nDate\ndate\ntimestamp of data entry\n\n\nShip_Type\ncategorical\ntypes of vessel\n\n\nRoute_Type\ncategorical\ntypes of route\n\n\nEngine_Type\ncategorical\ntypes of ship engine\n\n\nMaintenance_Status\ncategorical\ncurrent maintenance status\n\n\nSpeed_Over_Ground_knots\nnumerical\naverage speed (knots)\n\n\nEngine_Power_kW\nnumerical\nengine power output (kW)\n\n\nDistance_Traveled_nm\nnumerical\ntotal distance travelled (nm)\n\n\nDraft_meters\nnumerical\ndraft of the vessel (m)\n\n\nWeather_Condition\ncategorical\nweather condition during operations\n\n\nCargo_Weight_tons\nnumerical\nweight of goods on the ship (tons)\n\n\nOperational_Cost_USD\nnumerical\ntotal operational cost per voyage (USD)\n\n\nRevenue_per_Voyage_USD\nnumerical\ntotal revenue generated per voyage (USD)\n\n\nTurnaround_Time_hours\nnumerical\ntime taken per voyage (hours)\n\n\nEfficiency_nm_per_kWh\nnumerical\nenergy efficiency (nm/kWh)\n\n\nSeasonal_Impact_Score\nnumerical\nnot listed in Kaggle\n\n\nWeekly_Voyage_Count\ninteger\ntotal no. of voyage per week\n\n\nAverage_Load_Percentage\npercentage (%)\nnot listed in Kaggle"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#remove-columns",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#remove-columns",
    "title": "Take-home Exercise 1",
    "section": "3.2 Remove Columns",
    "text": "3.2 Remove Columns\nFrom the table, we will keep all the categorical and numerical columns to gain further insights on this dataset. There are 3 columns that we should remove from this dataset, which are Date, Seasonal_Impact_Score and Average_Load_Percentage.\n\nDate: This column is removed because it only consists of the timestamp of the data entry, which is not necessarily value-add to this analysis.\nSeasonal_Impact_Score: This column is removed because there is no description of how the value in this column is calculated. As there is no details on the column calculation, there will be no insights gained from analysing this column.\nAverage_Load_Percentage: This column is removed because there is no description and source of the column calculation, hence, there is no need to use this column for the analysis.\n\nThe 3 columns will be removed using the code chunk below:\n\nship &lt;- ship %&gt;% select(-c(\"Date\", \"Seasonal_Impact_Score\", \"Average_Load_Percentage\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#handling-missing-value",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#handling-missing-value",
    "title": "Take-home Exercise 1",
    "section": "3.3 Handling Missing Value",
    "text": "3.3 Handling Missing Value\n\n3.3.1 Categorical Column\n\ntable(ship$Ship_Type)\n\n\n  Bulk Carrier Container Ship   Fish Carrier           None         Tanker \n           669            635            653            136            643 \n\n\n\ntable(ship$Route_Type)\n\n\n     Coastal    Long-haul         None   Short-haul Transoceanic \n         650          686          136          626          638 \n\n\n\ntable(ship$Engine_Type)\n\n\n              Diesel Heavy Fuel Oil (HFO)                 None \n                 892                  853                  136 \n       Steam Turbine \n                 855 \n\n\n\ntable(ship$Maintenance_Status)\n\n\nCritical     Fair     Good     None \n     860      867      873      136 \n\n\n\ntable(ship$Weather_Condition)\n\n\n    Calm Moderate     None    Rough \n     893      891      136      816 \n\n\n\nship &lt;- ship[ship$Ship_Type != \"None\", ]\nship &lt;- ship[ship$Route_Type != \"None\", ]\nship &lt;- ship[ship$Engine_Type != \"None\", ]\nship &lt;- ship[ship$Maintenance_Status != \"None\", ]\nship &lt;- ship[ship$Weather_Condition != \"None\", ]\n\n\ndim(ship)\n\n[1] 2127   15\n\n\n\n\n3.3.2 Numerical Column\nIn this section, we will further clean numerical data type column to ensure the entire dataset is clean. The code chunks below will check the sum of null values of each numerical column.\n\nsum(is.na(ship$Speed_Over_Ground_knots))\n\n[1] 0\n\n\n\nsum(is.na(ship$Engine_Power_kW))\n\n[1] 0\n\n\n\nsum(is.na(ship$Distance_Traveled_nm))\n\n[1] 0\n\n\n\nsum(is.na(ship$Draft_meters))\n\n[1] 0\n\n\n\nsum(is.na(ship$Cargo_Weight_tons))\n\n[1] 0\n\n\n\nsum(is.na(ship$Operational_Cost_USD))\n\n[1] 0\n\n\n\nsum(is.na(ship$Revenue_per_Voyage_USD))\n\n[1] 0\n\n\n\nsum(is.na(ship$Turnaround_Time_hours))\n\n[1] 0\n\n\n\nsum(is.na(ship$Efficiency_nm_per_kWh))\n\n[1] 0\n\n\n\nsum(is.na(ship$Weekly_Voyage_Count))\n\n[1] 0\n\n\n\nglimpse(ship)\n\nRows: 2,127\nColumns: 15\n$ Ship_Type               &lt;chr&gt; \"Fish Carrier\", \"Container Ship\", \"Bulk Carrie…\n$ Route_Type              &lt;chr&gt; \"Short-haul\", \"Long-haul\", \"Transoceanic\", \"Tr…\n$ Engine_Type             &lt;chr&gt; \"Steam Turbine\", \"Diesel\", \"Steam Turbine\", \"D…\n$ Maintenance_Status      &lt;chr&gt; \"Good\", \"Fair\", \"Fair\", \"Fair\", \"Fair\", \"Criti…\n$ Speed_Over_Ground_knots &lt;dbl&gt; 10.38758, 20.74975, 21.05510, 13.74278, 18.616…\n$ Engine_Power_kW         &lt;dbl&gt; 1796.0574, 1648.5567, 915.2618, 1089.7218, 217…\n$ Distance_Traveled_nm    &lt;dbl&gt; 1060.4864, 658.8741, 1126.8225, 1445.2812, 723…\n$ Draft_meters            &lt;dbl&gt; 14.653083, 7.199261, 11.789063, 9.727833, 14.9…\n$ Weather_Condition       &lt;chr&gt; \"Rough\", \"Moderate\", \"Moderate\", \"Moderate\", \"…\n$ Cargo_Weight_tons       &lt;dbl&gt; 162.3947, 178.0409, 1737.3853, 260.5951, 1912.…\n$ Operational_Cost_USD    &lt;dbl&gt; 483388.00, 448543.40, 261349.61, 287718.38, 18…\n$ Revenue_per_Voyage_USD  &lt;dbl&gt; 883765.79, 394018.75, 87551.38, 676121.46, 776…\n$ Turnaround_Time_hours   &lt;dbl&gt; 63.24820, 49.41815, 22.40911, 64.15823, 47.476…\n$ Efficiency_nm_per_kWh   &lt;dbl&gt; 0.2903614, 0.4995945, 0.7029057, 1.3313431, 1.…\n$ Weekly_Voyage_Count     &lt;dbl&gt; 6, 9, 1, 8, 7, 3, 6, 2, 9, 4, 3, 7, 7, 2, 4, 3…\n\n\naverage operational cost per ship type, average revenue per ship type, stats of voyage per week"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#check-for-outliers-in-numerical-column",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#check-for-outliers-in-numerical-column",
    "title": "Take-home Exercise 1",
    "section": "3.4 Check for Outliers in Numerical Column",
    "text": "3.4 Check for Outliers in Numerical Column\nThere are total of 10 numerical columns that we can use for our statistical analysis. In this section, we will do an individual column check to see whether there is outliers affecting the column of the dataset.\n\nboxplot.stats(ship$Speed_Over_Ground_knots)$out\n\nnumeric(0)\n\n\n\nboxplot.stats(ship$Engine_Power_kW)$out\n\nnumeric(0)\n\n\n\nboxplot.stats(ship$Distance_Traveled_nm)$out\n\nnumeric(0)\n\n\n\nboxplot.stats(ship$Draft_meters)$out\n\nnumeric(0)\n\n\n\nboxplot.stats(ship$Operational_Cost_USD)$out\n\nnumeric(0)\n\n\n\nboxplot.stats(ship$Cargo_Weight_tons)$out\n\nnumeric(0)\n\n\n\nboxplot.stats(ship$Revenue_per_Voyage_USD)$out\n\nnumeric(0)\n\n\n\nboxplot.stats(ship$Turnaround_Time_hours)$out\n\nnumeric(0)\n\n\n\nboxplot.stats(ship$Efficiency_nm_per_kWh)$out\n\nnumeric(0)\n\n\n\nboxplot.stats(ship$Weekly_Voyage_Count)$out\n\nnumeric(0)\n\n\nThe result from the codes above shows that there are no potential outliers affecting the dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#derive-new-columns",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#derive-new-columns",
    "title": "Take-home Exercise 1",
    "section": "3.5 Derive New Columns",
    "text": "3.5 Derive New Columns\nTo gain more insights on this analysis, let us derive a new column to find out the profit gained on each voyage of the ships. The code chunk below will use mutate() to derive the new column.\n\nship &lt;- ship %&gt;% \n  mutate(Profit_per_Voyage_USD = Revenue_per_Voyage_USD - Operational_Cost_USD)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#profit-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#profit-analysis",
    "title": "Take-home Exercise 1",
    "section": "4.1 Profit Analysis",
    "text": "4.1 Profit Analysis\n\nprofit &lt;- ship[ship$Profit_per_Voyage_USD &gt;= 0, ]\n\nLet us plot a the distribution of profit earned per voyage using the histogram below.\n\nPlotCode\n\n\n\n\n\n\n\n\nThe histogram shows a normal distribution ranging from USD -500,000 to USD 1,000,000. The distribution of profit is symmetrical with the highest count at USD 250,000. Normal distribution shows that it is uncommon to have a very high profit, and it is also uncommon to get extreme losses from ship journey. The x-axis shows there are presence of negative profit value, ranging from USD 0 to USD -500,000. Although the occurrence is not as often, is is still a questionable event of why certain ships incur losses in the ship operations. The histogram roughly highlights financial variability in the ship and maritime industry.\n\n\n\nv1 &lt;- ggplot(data = ship, aes(x = Profit_per_Voyage_USD)) + \n  geom_histogram(bins = 50,\n                 color = \"black\",\n                 fill = \"grey\") + \n  coord_cartesian(xlim=c(-500000,1000000),\n                  ylim=c(0,80)) + \n  scale_x_continuous(\"Profit (USD)\",               \n                     breaks = seq(-500000, 1000000, by = 250000),\n                     labels = scales::comma) +\n  labs(\n    title = \"Profit Distribution of Ships per Voyage (USD)\",\n    y = \"Count\"\n  ) + \n  theme_minimal()\n\nggplotly(v1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loss-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loss-analysis",
    "title": "Take-home Exercise 1",
    "section": "4.2 Loss Analysis",
    "text": "4.2 Loss Analysis\n\n4.2.1 Loss Incurred by Ship Types\nAfter the distribution plot, we are interested to find out the reason of loss incurred in the maritime industry. Let us create a new dataframe to do further analysis on the losses.\n\nloss &lt;- ship[ship$Profit_per_Voyage_USD &lt; 0, ]\n\n\nPlotCode\n\n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\nThe plot suggests that bulk carrier incurs the most losses as compared to other types of ship. Bulk carrier has a mean loss of USD 181,054 with a margin of error of USD 10,185. Other ship types incur a mean loss ranging from USD 140,000 to 160,000. From this plot, we are curious on why bulk carriers incur such a big loss in operating their ship.\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean Loss:\", mean, \"+/-\", sem)\n}\n\nv2 &lt;- ggplot(data=loss, \n                   aes(x = Ship_Type),\n) +\n  stat_summary(aes(y = Profit_per_Voyage_USD, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = Profit_per_Voyage_USD),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  ) + \n  labs(\n    title = \"Loss per Voyage by Ship Type\",\n    x = \"Ship Type\",\n    y = \"Profit/Loss per Voyage (USD)\"\n  )\n\ngirafe(ggobj = v2,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n4.2.2 Bulk Carrier Analysis\nFrom the previous plot, we want to further deep dive into bulk carrier ship to find out the reason of such a big loss in operating this ship. Hence, let us derive a new dataframe by filtering out only the bulk carriers data using the code below.\n\nbc &lt;- ship[ship$Ship_Type == \"Bulk Carrier\",]\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nThere are 3 types of engines that could be used to operate a bulk carrier, Steam Turbine, Heavy Fuel Oil and Diesel. The boxplot suggests that, on average, it requires more cost to use Heavy Fuel Oil. The half eye graph shows the distribution shape of the operational cost. Heavy Fuel Oil and Steam Turbine have higher peaks, while Diesel has lower density distribution. This means that the cost of using Diesel is more spread out as compared to other engine types."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#ship-type-and-route-type-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#ship-type-and-route-type-analysis",
    "title": "Take-home Exercise 1",
    "section": "4.3 Ship Type and Route Type Analysis",
    "text": "4.3 Ship Type and Route Type Analysis\n\n4.3.1 Loss Incurred by Each Ship Type and Route Type\nIn this section, we will further breakdown each ship type according to the route type and analyse the profit and loss incurred from each voyage.\n\nPlotCode\n\n\n\n\n\n\n\n\nThis code visualizes the count of ship type by each route type that incurred losses during the ship operations. The chart suggests that container ship that uses long-haul route incurred the most losses as compared to other types of route. The second most loss incurred is bulk carrier that uses coastal route and also short-haul. Container ships and bulk carrier typically weighs significantly higher than other types of ship. Hence, the high operational cost that outweighs the revenue of the ship operations.\n\n\n\nv4 &lt;- ggplot(data = loss, \n            aes(x = Ship_Type, fill = Route_Type)) +\n  geom_bar(stat = \"count\", \n           position = \"dodge\", \n           width = 0.7) +\n  scale_y_continuous(limits = c(0, 50)) +\n  scale_fill_manual(values = c(\"steelblue\", \"slategray\", \"darkslategray\", \"lightsteelblue\")) +\n  theme_minimal() +\n  labs(x = \"Ship Type\", \n       y = \"Count\", \n       title = \"Ship Type Distribution by Route Type that Incurred Loss\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\nggplotly(v4)\n\n\n\n\n\n\n4.3.2 Operational Cost\nAccording to the previous plot, container ship has the most count of ship operations that incurred losses. Hence, we are interested to find out the operational cost distribution of each type of ships from all the data entry that has higher cost than revenue.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nThe half eye distribution shows that container ship graph is skewed to the left and has higher count for operational cost above the median point. While bulk carrier and fish carrier distribution is also heavily left-skewed, the median point is still lower than container ship’s data.\n\n\n\nv5 &lt;- ggplot(loss, \n       aes(x = Ship_Type, \n           y = Operational_Cost_USD)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA,\n               position = position_nudge(x = -0.2)) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  scale_y_continuous(\"Operational Cost (USD)\",               \n                     breaks = seq(0, 500000, by = 100000),\n                     labels = scales::comma) +\n  labs(\n    title = \"Operational Cost Distribution of Bulk Carrier by Engine Type (USD)\"\n  ) + \n  coord_flip() +\n  theme_minimal()\n\nv5\n\n\n\n\n\n\n4.3.3 Mean Weights of Goods in the Ship\nAccording to the previous figure, we have concluded that the high operational cost of container ship and bulk carrier could be due to the cargo weights, which results in more maintenance needs or machine requirements. Hence, we will plot a visual to see whether container ships and bulk carriers has significantly more weights.\n\nPlotCode\n\n\n\n\n\n\n\n\nThe plot above proves that container ship and bulk carrier don’t have the highest weight. In fact, fish carrier has the highest mean weight as compared to the other ship types. This means that the cause of high operational cost of container ship and bulk carrier could be due to other possible reasons.\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean Weight:\", mean, \"+/-\", sem)\n}\n\nv6 &lt;- ggplot(data=loss, \n                   aes(x = Ship_Type),\n) +\n  stat_summary(aes(y = Cargo_Weight_tons, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"steelblue\"\n  ) +\n  stat_summary(aes(y = Cargo_Weight_tons),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  ) + \n  labs(\n    title = \"Mean Weights of Ship Types that Incurred Loss\",\n    x = \"Ship Type\",\n    y = \"Weight (tons)\"\n  )\n\ngirafe(ggobj = v6,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n4.3.4 Median Speed of Each Ship Types\nLet us plot a boxplot to find out whether the speed of the ship affects the high operational cost in shipping industry.\n\nPlotCode\n\n\n\n\n\n\n\n\nFrom this boxplot, we can see that container ship has the highest median of ship speed. The high operational cost of container ship could potentially be caused by the machine or engine requirements to operate faster ships. This could also be caused by other required logistics that might be more complicated in container ship as compared to a fish carrier.\n\n\n\nv7 &lt;- ggplot(loss, \n       aes(x = Ship_Type, \n           y = Speed_Over_Ground_knots)) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA,\n               position = position_nudge(x = -0.2)) +\n  labs(\n    title = \"Boxplot of Ship Speed by Ship Type\",\n    x = \"Ship Type\",\n    y = \"Speed\"\n  )\n\nggplotly(v7)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#maintenance-status-of-ships-that-incurs-losses",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#maintenance-status-of-ships-that-incurs-losses",
    "title": "Take-home Exercise 1",
    "section": "4.4 Maintenance Status of Ships That Incurs Losses",
    "text": "4.4 Maintenance Status of Ships That Incurs Losses\nIn this section, we will highlight ships with critical maintenance status. The purpose is to focus on ships with bad maintenance quality and pay attention to ship types that require more maintenance.\nBefore we create the plot, let us calculate the percentage of ships with critical maintenance status using the code below.\n\nc8 &lt;- ship %&gt;%\n  group_by(Ship_Type) %&gt;%\n  summarise(\n    Total = n(),\n    Critical_Count = sum(Maintenance_Status == \"Critical\"),\n    Critical_Percentage = (Critical_Count / Total) * 100\n  )\n\nAfter deriving a variable to calculate the percentage, now let us plot and compare the maintenance status of each ship type.\n\nPlotCode\n\n\n\n\n\n\n\n\nFrom the bar chart, container ship has the highest percentage of ships that is not well-maintained. A well-maintained ship can help reduce the repair cost and the frequency of repairs, minimize downtime to help ship operate efficiently and it will also help them attract more businesses to use the service. This data shows that we should pay more attention to maintenance to help a smoother operations in the maritime industry.\n\n\n\nv8 &lt;- ggplot(c8, aes(x = Ship_Type,\n                             y = Critical_Percentage,\n                             fill = Ship_Type)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = paste0(round(Critical_Percentage, 1), \"%\")),\n            vjust = -0.5) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(title = \"Percentage of Critical Maintenance Status by Ship Type\",\n       x = \"Ship Type\",\n       y = \"Percentage of Critical Status\") +\n  theme_minimal()\n\nggplotly(v8)"
  }
]